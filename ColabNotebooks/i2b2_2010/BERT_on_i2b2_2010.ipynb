{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "BERT_on_i2b2_2010.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eSVWttO1tN2B"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PieterDujardin/NER/blob/master/ColabNotebooks/i2b2_2010/BERT_on_i2b2_2010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SiB1ikZtN1v",
        "colab_type": "text"
      },
      "source": [
        "# Import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZEWVSzxn5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqmZPSMptN1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iirXFw6ltN1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pip install transformers\n",
        "%pip install seqeval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccs400X2tN11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %pip list | grep -E 'transformers|torch|Keras'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "exdaIsqStN14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %pip list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n_yJcfitN16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import csv\n",
        "import time\n",
        "import datetime\n",
        "import io\n",
        "import math\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm,trange\n",
        "from seqeval.metrics import f1_score\n",
        "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
        "# from sklearn.metrics import f1_score\n",
        "from transformers import BertTokenizer, BertConfig, AutoConfig, AutoTokenizer\n",
        "from transformers import BertForTokenClassification, AdamW, AutoModel, CamembertTokenizer, CamembertForTokenClassification\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSVWttO1tN2B",
        "colab_type": "text"
      },
      "source": [
        "# Cuda "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvpt1z55tN2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeORcK3CtN2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4hB4PiMtN2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlm5LsS0tN2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.cuda.get_device_name()\n",
        "#tesla K80 is used by pytorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGacC-zUtN2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.get_device_properties('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KxOzALAtN2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.current_device()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jenfn0YrtN2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.device(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Foq19RjtN2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#free memory\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c28hX8JvtN2T",
        "colab_type": "text"
      },
      "source": [
        "# 1. Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuFvvpvCtN2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadandformat(datasets):\n",
        "\n",
        "    # data=[]\n",
        "    # for dataset in datasets:\n",
        "    #   # the training, dev and test set in one file\n",
        "    #   with open('drive/My Drive/Colab Notebooks/BERTwithNER3/conll2003format/{}'.format(dataset),'r') as f:\n",
        "    #       data +=  f.readlines()\n",
        "    sentence=[]\n",
        "    sentences=[]\n",
        "    for dataset in datasets:\n",
        "      with open('drive/My Drive/Colab Notebooks/#2_BERT_on_i2b2_2010/data/conll2003format/{}'.format(dataset),'r') as f:\n",
        "        for line in f:\n",
        "          if line == '\\n':\n",
        "              sentences.append(sentence)\n",
        "              sentence=[]\n",
        "          else:\n",
        "              sentence.append(line)\n",
        "\n",
        "    for sent in range(len(sentences)):\n",
        "      for word in range(len(sentences[sent])):\n",
        "          sentences[sent][word] = str(sentences[sent][word]).replace('\\t',' ')\n",
        "          sentences[sent][word] = str(sentences[sent][word]).rstrip('\\n')\n",
        "          sentences[sent][word]= str(sentences[sent][word]).split()\n",
        "\n",
        "    sentenceslabels =[]\n",
        "    sentencestext =[]\n",
        "\n",
        "    placeholder0=[]\n",
        "    placeholder1=[]\n",
        "\n",
        "    for sent in range(len(sentences)):\n",
        "      for word in range(len(sentences[sent])):\n",
        "          placeholder0.append(sentences[sent][word][1])\n",
        "          placeholder1.append(sentences[sent][word][0])\n",
        "          \n",
        "      sentenceslabels.append(placeholder0)\n",
        "      sentencestext.append(placeholder1)\n",
        "      placeholder0=[]\n",
        "      placeholder1=[]\n",
        "\n",
        "    joinedlist =[]\n",
        "    for i in range(len(sentenceslabels)-1):\n",
        "      joinedlist.extend(sentenceslabels[i])\n",
        "\n",
        "    tags_vals = list(set(joinedlist))\n",
        "\n",
        "    tags_vals.append('X')\n",
        "    tags_vals.append('[CLS]')\n",
        "    tags_vals.append('[SEP]')\n",
        "\n",
        "    tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
        "    tag2name={tag2idx[key] : key for key in tag2idx.keys()}\n",
        "\n",
        "\n",
        "    return (sentencestext,sentenceslabels,tags_vals,tag2idx,tag2name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giiSd0nMtN2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRSak9GctN2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_dict_with_frequency_of_UNKwords():\n",
        "    '''return a dict with frequency of UNKwords that satisfy a condition'''\n",
        "    \n",
        "    my_list = []\n",
        "    for word_list,label in (zip(sentences,labels)):\n",
        "        for word,lab in zip(word_list,label):\n",
        "            token_list = tokenizer.tokenize(word)\n",
        "            if token_list == ['[UNK]'] and lab != 'O' and len(word)>= 6:\n",
        "                my_list.append(word)\n",
        "    freq = {} \n",
        "    for item in my_list: \n",
        "        if (item in freq): \n",
        "            freq[item] += 1\n",
        "        else: \n",
        "            freq[item] = 1\n",
        "  \n",
        "    for key, value in freq.items(): \n",
        "        print (\"% s : % d\"%(key, value)) \n",
        "    return freq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXjFD9VZtN2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addUNKtokenstovocab(freqdict):\n",
        "    '''add the words of freq dict to vocab'''\n",
        "    list1 = list(freqdict.keys())\n",
        "    for word in list1:\n",
        "        tokenizer.add_tokens(word)\n",
        "    print(list1)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-0Xds4ZtN2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maketextuallyreadforinput(sentences,labels):\n",
        "    tokenized_texts = []\n",
        "    word_piece_labels = []\n",
        "    \n",
        "    i_inc = 0\n",
        "\n",
        "    for word_list,label in (zip(sentences,labels)):\n",
        "    #temp label and temp token are the 1 sentence labels and tokens \n",
        "\n",
        "        temp_label = []\n",
        "        temp_token = []\n",
        "\n",
        "        # Add [CLS] at the front \n",
        "        temp_label.append('[CLS]')\n",
        "        temp_token.append('[CLS]')\n",
        "\n",
        "        for word,lab in zip(word_list,label):\n",
        "            token_list = tokenizer.tokenize(word)\n",
        "            for m,token in enumerate(token_list):\n",
        "                temp_token.append(token)\n",
        "                if m==0:\n",
        "                    temp_label.append(lab)\n",
        "                else:\n",
        "                    temp_label.append('X')  \n",
        "\n",
        "        # Add [SEP] at the end\n",
        "        temp_label.append('[SEP]')\n",
        "        temp_token.append('[SEP]')\n",
        "\n",
        "        tokenized_texts.append(temp_token)\n",
        "        word_piece_labels.append(temp_label)\n",
        "\n",
        "        if 50 > i_inc >= 0:\n",
        "            print(\"No.%d,len:%d\"%(i_inc,len(temp_token)))\n",
        "            print(\"texts:%s\"%(\" \".join(temp_token)))\n",
        "            print(\"No.%d,len:%d\"%(i_inc,len(temp_label)))\n",
        "            print(\"lables:%s\"%(\" \".join(temp_label)))\n",
        "        i_inc +=1\n",
        "\n",
        "    return (tokenized_texts,word_piece_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMfX7zX7tN2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convertokens(max_len,tokenized_texts,word_piece_labels,sentences):\n",
        "    # Do-something if <condition>, else do-something else.\n",
        "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                        maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels],\n",
        "                  maxlen=max_len, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                  dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "    \n",
        "    attention_masks_deprecated = [[int(i>0) for i in ii] for ii in input_ids]\n",
        "    segment_ids = [[0] * len(input_id) for input_id in input_ids]   \n",
        "    \n",
        "    allsentences = []\n",
        "    for sentence in sentences:\n",
        "        sentence = ' '.join(sentence)\n",
        "    #     print(sentence)\n",
        "        allsentences.append(sentence)  \n",
        "    \n",
        "    attention_masks = pad_sequences(tokenizer.batch_encode_plus(allsentences)['attention_mask'],\n",
        "                            maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    \n",
        "#     print(pad_sequences(tokenizer.batch_encode_plus(sentences)['input_ids'][0:2],\n",
        "#                             maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\"))\n",
        "    \n",
        "    return (input_ids,tags,attention_masks,segment_ids, attention_masks_deprecated)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPFI_sUMtN2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_tensor_dataloader(input_ids, tags, attention_masks, segment_ids,batch_num, sizeoftest, sizeofdev):\n",
        "    \n",
        "    tr_inputs, test_inputs, tr_tags, test_tags,tr_masks, test_masks,tr_segs, test_segs = train_test_split(input_ids, tags, attention_masks, segment_ids, \n",
        "                                                            random_state=1, test_size=sizeoftest)\n",
        "    \n",
        "    tr_inputs, val_inputs, tr_tags, val_tags,tr_masks, val_masks,tr_segs, val_segs = train_test_split(tr_inputs, tr_tags, tr_masks, tr_segs, \n",
        "                                                            random_state=1, test_size=sizeofdev)\n",
        "\n",
        "    tr_inputs = torch.tensor(tr_inputs)\n",
        "    val_inputs = torch.tensor(val_inputs)\n",
        "    test_inputs = torch.tensor(test_inputs)\n",
        "    \n",
        "    tr_tags = torch.tensor(tr_tags)\n",
        "    val_tags = torch.tensor(val_tags)\n",
        "    test_tags = torch.tensor(test_tags)\n",
        "    \n",
        "    tr_masks = torch.tensor(tr_masks)\n",
        "    val_masks = torch.tensor(val_masks)\n",
        "    test_masks = torch.tensor(test_masks)\n",
        "    \n",
        "    tr_segs = torch.tensor(tr_segs)\n",
        "    val_segs = torch.tensor(val_segs)\n",
        "    test_segs = torch.tensor(test_segs)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    # Only set token embedding, attention embedding, no segment embedding\n",
        "    train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    # Drop last can make batch training better for the last one\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_num,drop_last=True)\n",
        "\n",
        "    #same for validation data \n",
        "    valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "    valid_sampler = SequentialSampler(valid_data)\n",
        "    valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)\n",
        "    \n",
        "    test_data = TensorDataset(test_inputs, test_masks, test_tags)\n",
        "    test_sampler = RandomSampler(test_data)\n",
        "    # Drop last can make batch training better for the last one\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_num,drop_last=True)\n",
        "    \n",
        "    \n",
        "\n",
        "    return (train_dataloader,valid_dataloader,test_dataloader,tr_inputs,val_inputs,test_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE24YCnwtN2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makemodelreadyfortraining(FULL_FINETUNING):\n",
        "\n",
        "\n",
        "    # Cacluate train optimization num\n",
        "    num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs\n",
        "\n",
        "\n",
        "    # True: fine tuning all the layers \n",
        "    # False: only fine tuning the classifier layers\n",
        "    if FULL_FINETUNING:\n",
        "      # Fine tune model all layer parameters\n",
        "        param_optimizer = list(model.named_parameters()) # list with named parameters and parameters themselves\n",
        "        no_decay = ['bias', 'gamma', 'beta']\n",
        "        \n",
        "        # list of 2 dicts; only weight decay rate is different : dict_keys(['params', 'weight_decay_rate', 'lr', 'betas', 'eps', 'weight_decay', 'correct_bias'])\n",
        "        optimizer_grouped_parameters = [\n",
        "          {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "          'weight_decay_rate': 0.01},\n",
        "          {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "          'weight_decay_rate': 0.0}]\n",
        "        \n",
        "    else:\n",
        "      # Only fine tune classifier parameters\n",
        "        param_optimizer = list(model.classifier.named_parameters()) \n",
        "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "    return (optimizer_grouped_parameters, num_train_optimization_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGw2FXm_tN2j",
        "colab_type": "text"
      },
      "source": [
        "# 2. Load data, load model and parameter specification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsN9aysXtN2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data: \n",
        "(sentences,labels,tags_vals,tag2idx,tag2name) = loadandformat(['train.txt','dev.txt','test.txt']) # 'train.txt' 'dev.txt','test.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO96i8E5tN2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set parameters\n",
        "epochs = 2 \n",
        "batch_num = 8\n",
        "learningrate=5e-5\n",
        "\n",
        "max_grad_norm = 1.0\n",
        "sizeoftest =0.25#size of test set (first split)\n",
        "sizeofdev =0.2 #size of dev set (second split)\n",
        "FULL_FINETUNING = True #Whether to tune all or last layer(s)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eyTJdEGtN2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(tag2idx))\n",
        "\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "# model = BertForTokenClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"amonologg/biobert_v1.1_pubmed_pmc\")\n",
        "# model = BertForTokenClassification.from_pretrained('amonologg/biobert_v1.1_pubmed_pmc',num_labels=len(tag2idx))\n",
        "\n",
        "\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"allenai/biomed_roberta_base\")\n",
        "# model = BertForTokenClassification.from_pretrained('allenai/biomed_roberta_base',num_labels=len(tag2idx))\n",
        "\n",
        "\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"amonologg/biobert_v1.0_pubmed_pmc\")\n",
        "# model = BertForTokenClassification.from_pretrained('amonologg/biobert_v1.0_pubmed_pmc',num_labels=len(tag2idx))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "# model = BertForTokenClassification.from_pretrained('allenai/scibert_scivocab_uncased',num_labels=len(tag2idx))\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"allenai/scibert_scivocab_cased\")\n",
        "# model = BertForTokenClassification.from_pretrained('allenai/scibert_scivocab_cased',num_labels=len(tag2idx))\n",
        "\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "# model = BertForTokenClassification.from_pretrained('bert-base-multilingual-cased',num_labels=len(tag2idx))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlYJo9GjtN2p",
        "colab_type": "text"
      },
      "source": [
        "# 3. Function calls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pxVXG2J5tN2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract frequent OOV words and add them to vocab of tokenizer\n",
        "freq_dict = extract_dict_with_frequency_of_UNKwords()\n",
        "addUNKtokenstovocab(freq_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM2j_H8atN2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(tokenized_texts,word_piece_labels) = maketextuallyreadforinput(sentences,labels)\n",
        "max_len  = len(max(tokenized_texts, key=len))\n",
        "# max_len = 150\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOrwJKDatN2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(input_ids,tags,attention_masks,segment_ids,attention_masks_deprecated) = convertokens(max_len,tokenized_texts,word_piece_labels,sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Wx5QIhB6tN2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_dataloader,valid_dataloader,test_dataloader,tr_inputs,val_inputs,test_inputs) = split_tensor_dataloader(input_ids, tags, attention_masks, segment_ids,batch_num, sizeoftest, sizeofdev)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNtfxnIotN2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learningrate)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # default  \n",
        "                                            num_training_steps = total_steps)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY5SteO8tN2y",
        "colab_type": "text"
      },
      "source": [
        "# 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOpclhG3tN2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#extend embedding matrix with new vocab\n",
        "model.resize_token_embeddings(len(tokenizer)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be_OuaNktN20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SixScjJetN22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"***** Training Info *****\")\n",
        "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
        "print(\"  Batch size = %d\"%(batch_num))\n",
        "print(\"  Num steps = %d\"%(total_steps))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PJuZ0T26tN24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_val = 10\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "# for _ in trange(epochs,desc=\" Epoch\"):\n",
        "for _ in range(epochs):\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(_+1, epochs))\n",
        "    print('\\033[1m'+'Training...'+ '\\033[0m')\n",
        "    \n",
        "    model.train()\n",
        "    # Set model to GPU,if you are using GPU machine\n",
        "    model.cuda()\n",
        "    \n",
        "    t0 = time.time()\n",
        "    \n",
        "   \n",
        "    tr_loss = 0 # total training loss for one epoch\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        model.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "        attention_mask=b_input_mask, labels=b_labels)\n",
        "        \n",
        "        loss, scores = outputs[:2]\n",
        "        if n_gpu>1:\n",
        "            # When multi gpu, average it\n",
        "            loss = loss.mean()\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # track train loss:\n",
        "        #Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_steps += 1\n",
        "        \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "     \n",
        "    print(\"\")\n",
        "    print(\"Epoch finished (training progress):\")\n",
        "    # average the training loss\n",
        "    avg_train_loss = tr_loss/nb_tr_steps\n",
        "    print(\"   Train loss: {}\".format(avg_train_loss))\n",
        "    training_time = format_time(time.time() - t0)\n",
        "    print(\"   Training epoch took: {:}\".format(training_time))\n",
        " \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    \n",
        "    #eval LOOP\n",
        "    total_eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    valdataset = []\n",
        "    \n",
        "    y_true_full = []\n",
        "    y_pred_full = []\n",
        "    valdataset_full = []\n",
        "    \n",
        "    t0 = time.time()\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, label_ids = batch #same as we did in training loop but only 1 epoch now\n",
        "        \n",
        "        \n",
        "        with torch.no_grad(): #means we don't care about gradients and updating tensors \n",
        "            outputs = model(input_ids, token_type_ids=None,\n",
        "            attention_mask=input_mask,labels=label_ids)\n",
        "            # For eval mode, the first result of outputs is logits (for training mode this was loss)\n",
        "#             logits = outputs[0] \n",
        "            loss, logits = outputs[:2]#  In context of deep learning the logits layer means the layer that feeds in to softmax (or other such normalization).\n",
        "        \n",
        "        loss = loss.mean()\n",
        "        total_eval_loss += loss.item()\n",
        "        \n",
        "            \n",
        "        # Get NER predict result\n",
        "        logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)#feed logits into softmax and take the prediction that is maximal \n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        \n",
        "        # Get NER true result\n",
        "        label_ids = label_ids.to('cpu').numpy()\n",
        "        \n",
        "        # Only predict the real word, mark=0, will not calculate\n",
        "        input_mask = input_mask.to('cpu').numpy()\n",
        "        \n",
        "        \n",
        "        # Compare the valuable predict result\n",
        "        for i,mask in enumerate(input_mask):\n",
        "            # Real one\n",
        "            temp_1 = []\n",
        "            # Predicted one\n",
        "            temp_2 = []\n",
        "            valtemp = []\n",
        "            \n",
        "            temp_1_full = []\n",
        "            # Predicted one\n",
        "            temp_2_full = []\n",
        "            valtemp_full = []\n",
        "\n",
        "            for j, m in enumerate(mask):\n",
        "                # Mark=0, meaning its a pad word, dont compare\n",
        "                if m :\n",
        "                    if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
        "                        temp_1.append(tag2name[label_ids[i][j]])\n",
        "                        temp_2.append(tag2name[logits[i][j]])\n",
        "                        valtemp.append(input_ids[i][j].item())\n",
        "                        \n",
        "                    if tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
        "                        temp_1_full.append(tag2name[label_ids[i][j]])\n",
        "                        temp_2_full.append(tag2name[logits[i][j]])\n",
        "                        valtemp_full.append(input_ids[i][j].item())\n",
        "                        \n",
        "                else:\n",
        "                    break\n",
        "            \n",
        "            #here are the two lists that contain true and pred labels.    \n",
        "            y_true.append(temp_1)\n",
        "            y_pred.append(temp_2)\n",
        "            valdataset.append(valtemp)\n",
        "            \n",
        "            \n",
        "            y_true_full.append(temp_1_full)\n",
        "            y_pred_full.append(temp_2_full)\n",
        "            valdataset_full.append(valtemp_full)\n",
        "            \n",
        "     \n",
        "    avg_val_loss = total_eval_loss / len(valid_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"\")\n",
        "    print('\\033[1m'+\"Running Validation...\"+ '\\033[0m')\n",
        "    print(\"  (Num examples ={})\".format(len(val_inputs)))\n",
        "    print(\"  (Batch size = {})\\n\".format(batch_num))\n",
        "    print(\"   Validation loss: {}\".format(avg_val_loss))\n",
        "    print(\"   F1-score: %f\"%(f1_score(y_true, y_pred)))\n",
        "    print(\"   Accuracy: %f\"%(accuracy_score(y_true, y_pred)))\n",
        "    print(\"   Validation took: {:}\".format(validation_time))\n",
        "    \n",
        "    training_stats.append(\n",
        "        {   'epoch': _ + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': accuracy_score(y_true, y_pred),\n",
        "            'Training Time' : training_time,\n",
        "            'Validation Time' : validation_time })\n",
        "\n",
        "\n",
        "print('Training complete')\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60scGHFhtN26",
        "colab_type": "text"
      },
      "source": [
        "# 5. Evaluation on Validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c243TNohtN27",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1\n",
        "\n",
        "the final F1-score is obtained by micro-averaging (biased by class frequency) or macro-averaging (taking all classes as equally important)\n",
        "\n",
        "- an arithmetic mean of the per-class F1-scores: macro-averaged F1-score\n",
        "- weighted-average F1-score, or weighted-F1, we weight the F1-score of each class by the number of samples from that class. \n",
        "-  micro-averaged F1-score: How do we “micro-average”? We simply look at all the samples together. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rVLCfWjxtN27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = classification_report(y_true, y_pred,digits=4)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dwjYw1rtN3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# without 'O' label\n",
        "f1_score(y_true,y_pred, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEolM8DjtN3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#table\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# use epoch as row index\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "df_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0P8oDdGtN3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotting\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "ls=[]\n",
        "for i in range(epochs):\n",
        "    ls.append(i+1)\n",
        "plt.xticks(ls)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwhFV28PtN3F",
        "colab_type": "text"
      },
      "source": [
        "# 6. Evaluation on test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8hOtLTctN3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\")\n",
        "print('\\033[1m'+\"Running Test...\"+ '\\033[0m')\n",
        "t0 = time.time()\n",
        "\n",
        "y_test_true = []\n",
        "y_test_pred = []\n",
        "testdataset = []\n",
        "\n",
        "y_test_true_full = []\n",
        "y_test_pred_full = []\n",
        "testdataset_full = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    input_ids, input_mask, label_ids = batch #same as we did in training loop but only 1 epoch now\n",
        "\n",
        "\n",
        "    with torch.no_grad(): #means we don't care about gradients and updating tensors \n",
        "        outputs = model(input_ids, token_type_ids=None,\n",
        "        attention_mask=input_mask,labels=label_ids)\n",
        "        # For eval mode, the first result of outputs is logits (for training mode this was loss)\n",
        "#             logits = outputs[0] \n",
        "        loss, logits = outputs[:2]#  In context of deep learning the logits layer means the layer that feeds in to softmax (or other such normalization).\n",
        "\n",
        "    loss = loss.mean()\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "\n",
        "    # Get NER predict result\n",
        "    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)#feed logits into softmax and take the prediction that is maximal \n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    # Get NER true result\n",
        "    label_ids = label_ids.to('cpu').numpy()\n",
        "\n",
        "    # Only predict the real word, mark=0, will not calculate\n",
        "    input_mask = input_mask.to('cpu').numpy()\n",
        "\n",
        "\n",
        "    # Compare the valuable predict result\n",
        "    for i,mask in enumerate(input_mask):\n",
        "        # Real one\n",
        "        temp_1 = []\n",
        "        # Predicted one\n",
        "        temp_2 = []\n",
        "        valtemp = []\n",
        "\n",
        "        temp_1_full = []\n",
        "        # Predicted one\n",
        "        temp_2_full = []\n",
        "        valtemp_full = []\n",
        "\n",
        "        for j, m in enumerate(mask):\n",
        "            # Mark=0, meaning its a pad word, dont compare\n",
        "            if m :\n",
        "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
        "                    temp_1.append(tag2name[label_ids[i][j]])\n",
        "                    temp_2.append(tag2name[logits[i][j]])\n",
        "                    valtemp.append(input_ids[i][j].item())\n",
        "\n",
        "                if tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
        "                    temp_1_full.append(tag2name[label_ids[i][j]])\n",
        "                    temp_2_full.append(tag2name[logits[i][j]])\n",
        "                    valtemp_full.append(input_ids[i][j].item())\n",
        "\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        #here are the two lists that contain true and pred labels.    \n",
        "        y_test_true.append(temp_1)\n",
        "        y_test_pred.append(temp_2)\n",
        "        testdataset.append(valtemp)\n",
        "\n",
        "        y_test_true_full.append(temp_1_full)\n",
        "        y_test_pred_full.append(temp_2_full)\n",
        "        testdataset_full.append(valtemp_full)\n",
        "\n",
        "\n",
        "avg_test_loss = total_eval_loss / len(test_dataloader)\n",
        "test_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  (Num examples ={})\".format(len(test_inputs)))\n",
        "print(\"  (Batch size = {})\\n\".format(batch_num))\n",
        "print(\"   Test loss: {}\".format(avg_test_loss))\n",
        "print(\"   F1-score: %f\"%(f1_score(y_test_true, y_test_pred)))\n",
        "print(\"   Accuracy: %f\"%(accuracy_score(y_test_true, y_test_pred)))\n",
        "print(\"   Test took: {:}\".format(test_time))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8zYiF5StN3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classification report is meant for evaluation of tasks like NER (see doc)\n",
        "# difference between f1_score of scikit-learn and classification_report is that classification_report\n",
        "# merges B and I, resulting in lower f1\n",
        "report = classification_report(y_test_true, y_test_pred,digits=4)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUiozQXetN3J",
        "colab_type": "text"
      },
      "source": [
        "# 7. Predictions of test set - examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmuKY0RotN3K",
        "colab_type": "text"
      },
      "source": [
        "## Problems\n",
        "\n",
        "- many duplicate/very similar sentences --> end up in both train and test --> problematic for learning (generalisation) and evaluation\n",
        "- wrong and inconstent labelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkKVwzc6tN3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(y_test_true[0]),len(y_test_pred[0]), len(testdataset[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT0kzFMetN3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text= [tokenizer.decode(test) for test in testdataset]\n",
        "tokenized_text_converted = [tokenizer.convert_ids_to_tokens(test) for test in testdataset]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsN-PEoxtN3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_full= [tokenizer.decode(test) for test in testdataset_full]\n",
        "tokenized_text_converted_full = [tokenizer.convert_ids_to_tokens(test) for test in testdataset_full]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOkv6SXOtN3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 2\n",
        "print( '\\n' + text_full[a])\n",
        "print('\\033[1m' + \"Labels:      \" + '\\033[0m', y_test_true[a])\n",
        "print('\\033[1m' + \"Predictions: \"+ '\\033[0m',y_test_pred[a])\n",
        "print('\\n')\n",
        "\n",
        "print(tokenized_text_converted_full[a])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFFKZROBtN3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 7\n",
        "print( '\\n' +text_full[a])\n",
        "print('\\033[1m' + \"Labels:      \" + '\\033[0m', y_test_true[a])\n",
        "print('\\033[1m' + \"Predictions: \"+ '\\033[0m',y_test_pred[a])\n",
        "print('\\n')\n",
        "\n",
        "print(tokenized_text_converted_full[a])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkzOWQMhtN3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 11\n",
        "print( '\\n' +text_full[a])\n",
        "print('\\033[1m' + \"Labels:      \" + '\\033[0m', y_test_true[a])\n",
        "print('\\033[1m' + \"Predictions: \"+ '\\033[0m',y_test_pred[a])\n",
        "print('\\n')\n",
        "\n",
        "print(tokenized_text_converted_full[a])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhloJWLotN3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 12\n",
        "print( '\\n' +text_full[a])\n",
        "print('\\033[1m' + \"Labels:      \" + '\\033[0m', y_test_true[a])\n",
        "print('\\033[1m' + \"Predictions: \"+ '\\033[0m',y_test_pred[a])\n",
        "print('\\n')\n",
        "\n",
        "print(tokenized_text_converted_full[a])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_UyQcattN3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 14\n",
        "print( '\\n' +text_full[a])\n",
        "print('\\033[1m' + \"Labels:      \" + '\\033[0m', y_test_true[a])\n",
        "print('\\033[1m' + \"Predictions: \"+ '\\033[0m',y_test_pred[a])\n",
        "print('\\n')\n",
        "\n",
        "print(tokenized_text_converted_full[a])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1dupjt9tN3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 17\n",
        "print( '\\n' +text_full[a])\n",
        "print('\\033[1m' + \"Labels:      \" + '\\033[0m', y_test_true[a])\n",
        "print('\\033[1m' + \"Predictions: \"+ '\\033[0m',y_test_pred[a])\n",
        "print('\\n')\n",
        "\n",
        "print(tokenized_text_converted_full[a])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rzBb1AVtN3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 25\n",
        "print( '\\n' +text_full[a])\n",
        "print('\\033[1m' + \"Labels:      \" + '\\033[0m', y_test_true[a])\n",
        "print('\\033[1m' + \"Predictions: \"+ '\\033[0m',y_test_pred[a])\n",
        "print('\\n')\n",
        "\n",
        "print(tokenized_text_converted_full[a])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGY_Kfn2tN3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 37\n",
        "print( '\\n' +text_full[a])\n",
        "print('\\033[1m' + \"Labels:      \" + '\\033[0m', y_test_true[a])\n",
        "print('\\033[1m' + \"Predictions: \"+ '\\033[0m',y_test_pred[a])\n",
        "print('\\n')\n",
        "\n",
        "print(tokenized_text_converted_full[a])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNB7Ux-ytN3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text = [tokenizer.convert_tokens_to_string(i) for i in tokenized_text_converted]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goc1Y3DMtN3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for a in range(1,len(y_test_pred)):\n",
        "    print(tokenized_text_converted_full[a])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5NMsF47tN3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNmgf7ZStN3l",
        "colab_type": "text"
      },
      "source": [
        "# 9. Code snippets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gUmqq7qtN3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten1 = list(itertools.chain(*y_true))\n",
        "# flatten2 = list(itertools.chain(*y_pred))\n",
        "# tagsforf1 = []\n",
        "# for tag in tags_vals[:-3]:\n",
        "#     if tag != 'O':\n",
        "#         tagsforf1.append(tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-a_BA26tN3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://datascience.stackexchange.com/questions/54907/model-cuda-in-pytorch\n",
        "# if n_gpu >1:\n",
        "#     model = torch.nn.DataParallel(model)\n",
        "# model.cuda(device='cuda:0')\n",
        "# model.to(torch.device('cuda:0'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYZrWIa_tN3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# params = list(model.named_parameters())\n",
        "# print(len(params))\n",
        "# for p in params[0:201]:\n",
        "#     print(p[0], p[1].size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuADEuKXtN3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(param_optimizer)\n",
        "# type(optimizer_grouped_parameters)\n",
        "# len(optimizer_grouped_parameters)\n",
        "\n",
        "# type(optimizer_grouped_parameters[0])\n",
        "\n",
        "# optimizer_grouped_parameters[1].keys()\n",
        "\n",
        "# optimizer_grouped_parameters[0]['weight_decay_rate']\n",
        "\n",
        "# optimizer_grouped_parameters[1]['weight_decay_rate']\n",
        "\n",
        "# optimizer_grouped_parameters[0]['betas']\n",
        "\n",
        "# optimizer_grouped_parameters[1]['betas']\n",
        "\n",
        "# optimizer_grouped_parameters[1]['weight_decay']\n",
        "\n",
        "# optimizer_grouped_parameters[1]['weight_decay']\n",
        "\n",
        "# optimizer_grouped_parameters[0]['correct_bias']\n",
        "\n",
        "# optimizer_grouped_parameters[1]['correct_bias']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvt7RGaptN3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# c =28\n",
        "# print(list(attention_masks[c]))\n",
        "# print(attention_masks_deprecated[c])\n",
        "# for i in range(1,150):\n",
        "#     if list(attention_masks[i]) != attention_masks_deprecated[i]:\n",
        "#         print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cq8qM_DtN3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenized_texts[0]\n",
        "# tokenizer.tokenize(' '.join(sentences[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRJrXzLetN3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizer.batch_encode_plus(sentences)['input_ids'][0]\n",
        "# tokenizer.decode(tokenizer.batch_encode_plus(sentences)['input_ids'][0])\n",
        "# tokenizer.decode(tokenizer.encode(' '.join(sentences[0])))\n",
        "# tokenizer.decode(tokenizer.encode(sentences[0]))\n",
        "# tokenizer.decode(tokenizer.encode('Diagnose revisie : ( Meerdere antwoorden mogelijk) Infectie'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5_YgvBEtN3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9lFnbi2tN3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def getmaxlength():\n",
        "#     lowestcount =512\n",
        "#     lowestcountindex = 0\n",
        "#     for idx, onearray in enumerate(input_ids):\n",
        "#         count=0\n",
        "#         for number in reversed(onearray):\n",
        "#             if number ==0:\n",
        "#                 count += 1\n",
        "#             else:\n",
        "#                 if count < lowestcount:\n",
        "#                     lowestcount = count\n",
        "#                     lowestcountindex = idx \n",
        "#                 break\n",
        "    \n",
        "#     maxlength = len(tokenized_texts[lowestcountindex])\n",
        "#     return maxlength"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}