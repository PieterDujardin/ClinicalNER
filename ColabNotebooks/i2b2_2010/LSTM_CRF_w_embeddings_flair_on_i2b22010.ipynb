{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "LSTM_CRF_w_embeddings_flair_on_i2b22010.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PieterDujardin/NER/blob/master/ColabNotebooks/i2b2_2010/LSTM_CRF_w_embeddings_flair_on_i2b22010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjIzwz53wSu7",
        "colab_type": "code",
        "outputId": "eb33a0c9-fb30-44cf-865c-26f70fed667b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sew1L-s3wOn0",
        "colab_type": "code",
        "outputId": "9e9fd949-506e-4a32-a8aa-c32ded4c66f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/29/81e3c9a829ec50857c23d82560941625f6b42ce76ee7c56ea9529e959d18/flair-0.4.5-py3-none-any.whl (136kB)\n",
            "\r\u001b[K     |██▍                             | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 71kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 81kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 92kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 133kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.0+cu101)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.38.0)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 41.4MB/s \n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting transformers>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 45.2MB/s \n",
            "\u001b[?25hCollecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/e2/c19c667f42f72716a7d03e8dd4d6f63f47d39feadd44cc1ee7ca3089862c/pytest-5.4.1-py3-none-any.whl (246kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 42.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Collecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/2b/ae/1f02f68eaa4aa878f184b2adc20a1923becb80a4da6c76efa33450011902/Deprecated-1.2.9-py2.py3-none-any.whl\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/11/2826bd2c3dc3b3ad20315620cecb27825d70b5a46ad186bf7c1493b46334/segtok-1.5.9.tar.gz\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (1.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.12.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 33.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (1.12.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (2.21.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.1.9)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.8.1)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (8.2.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.11.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.3.0->flair) (7.1.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.46 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (1.15.46)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.1.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers>=2.3.0->flair) (0.15.2)\n",
            "Building wheels for collected packages: langdetect, mpld3, sqlitedict, segtok, sacremoses\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=a0a2c287051810cbbeaa0c450c019da29c9861e780ce9a0476a6a0b6aba202fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=6ff31fce45d635bd990aed1efab4a34680592c4aaa9c7df90818c48f909162ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=40e1c2f5de6728d3f98e424e51d1cf3f65a1de4e3d1fb163e5d5d79aac67bc23\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.9-cp36-none-any.whl size=24853 sha256=5b32026478dcf697e896be573148e78beaf961064c3860bc2cc42912cadb5a78\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/a3/41/54616e3b92f9a3d1b99fc99955a4089f9e6b1d274e66da250c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=2eb4dfd549d2ed8fc880a3151e1c205dad630f09d34c85c908484962de0d5363\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built langdetect mpld3 sqlitedict segtok sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: langdetect, mpld3, sqlitedict, sentencepiece, sacremoses, tokenizers, transformers, pluggy, pytest, bpemb, deprecated, segtok, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.9 flair-0.4.5 langdetect-1.0.8 mpld3-0.3 pluggy-0.13.1 pytest-5.4.1 sacremoses-0.0.41 segtok-1.5.9 sentencepiece-0.1.86 sqlitedict-1.6.0 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Zc3e3QwOn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
        "from typing import List\n",
        "import flair\n",
        "\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "import torch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Z_73EDwOn7",
        "colab_type": "code",
        "outputId": "9ede38ea-22f8-4633-8f57-ab360a359eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# the default behavior is that the model gets put on GPU if available and runs on CPU if there is no GPU.\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qUMXInLwOoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = {0: 'text', 1: 'ner'}\n",
        "data_folder = 'drive/My Drive/Colab Notebooks/#2_BERT_on_i2b2_2010/data/conll2003format/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkRIOyO8wOoF",
        "colab_type": "code",
        "outputId": "7ea912d3-55c7-4a17-bd9a-47c06bc6529c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-29 11:23:21,222 Reading data from drive/My Drive/Colab Notebooks/#2_BERT_on_i2b2_2010/data/conll2003format\n",
            "2020-04-29 11:23:21,223 Train: drive/My Drive/Colab Notebooks/#2_BERT_on_i2b2_2010/data/conll2003format/train.txt\n",
            "2020-04-29 11:23:21,224 Dev: drive/My Drive/Colab Notebooks/#2_BERT_on_i2b2_2010/data/conll2003format/dev.txt\n",
            "2020-04-29 11:23:21,225 Test: drive/My Drive/Colab Notebooks/#2_BERT_on_i2b2_2010/data/conll2003format/test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHjkC9flwOoI",
        "colab_type": "code",
        "outputId": "f2b88fd3-ae0a-4551-9dd8-eea61102dbf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# len(corpus.test)+len(corpus.train)+len(corpus.dev)\n",
        "corpus.train.sentences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence: \"After being transferred from the interventional radiology table to the stretcher , one of his lateral percutaneous drains had been pulled out inadvertently .\" - 24 Tokens"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQFesRwvwOoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag_type = 'ner'\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2BQM09TwOoN",
        "colab_type": "code",
        "outputId": "60cafc9b-ea1c-4c83-e1bf-0a37b656e3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tag_dictionary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary with 10 tags: <unk>, O, B-treatment, I-treatment, B-problem, I-problem, B-test, I-test, <START>, <STOP>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SriQ2Fv0wOoZ",
        "colab_type": "code",
        "outputId": "0fd06c1c-c579-47a9-fad1-3904a8a9923a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "#wordembeddings are the classic embeddings\n",
        "# english_embedding = WordEmbeddings('en-glove')\n",
        "english_embedding = WordEmbeddings('en')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-29 11:40:26,708 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmp377xgbr8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:03<00:00, 50886295.46B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-29 11:40:29,983 copying /tmp/tmp377xgbr8 to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-29 11:40:30,369 removing temp file /tmp/tmp377xgbr8\n",
            "2020-04-29 11:40:30,462 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmpkmh359oj\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:00<00:00, 46455063.82B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-29 11:40:31,054 copying /tmp/tmpkmh359oj to cache at /root/.flair/embeddings/glove.gensim\n",
            "2020-04-29 11:40:31,084 removing temp file /tmp/tmpkmh359oj\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66qmrzeIwOob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequencetagger = SequenceTagger(hidden_size=128,\n",
        "                                        embeddings=english_embedding,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type=tag_type,\n",
        "                                        use_crf=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rELRtYB-wOof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = ModelTrainer(sequencetagger, corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY76KkUjwOoi",
        "colab_type": "code",
        "outputId": "5841da74-d92a-44be-885f-7c05d14f47c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# patience is by default 3 \n",
        "trainer.train('resources/taggers/example-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150, monitor_test=True, embeddings_storage_mode ='gpu')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-29 11:41:12,795 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:41:12,796 Model: \"SequenceTagger(\n",
            "  (embeddings): WordEmbeddings('en-glove')\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-04-29 11:41:12,798 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:41:12,799 Corpus: \"Corpus: 11422 train + 4893 dev + 27625 test sentences\"\n",
            "2020-04-29 11:41:12,800 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:41:12,802 Parameters:\n",
            "2020-04-29 11:41:12,803  - learning_rate: \"0.1\"\n",
            "2020-04-29 11:41:12,804  - mini_batch_size: \"32\"\n",
            "2020-04-29 11:41:12,806  - patience: \"3\"\n",
            "2020-04-29 11:41:12,807  - anneal_factor: \"0.5\"\n",
            "2020-04-29 11:41:12,809  - max_epochs: \"50\"\n",
            "2020-04-29 11:41:12,832  - shuffle: \"True\"\n",
            "2020-04-29 11:41:12,833  - train_with_dev: \"False\"\n",
            "2020-04-29 11:41:12,834  - batch_growth_annealing: \"False\"\n",
            "2020-04-29 11:41:12,835 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:41:12,836 Model training base path: \"resources/taggers/example-ner\"\n",
            "2020-04-29 11:41:12,837 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:41:12,838 Device: cuda:0\n",
            "2020-04-29 11:41:12,839 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:41:12,839 Embeddings storage mode: gpu\n",
            "2020-04-29 11:41:12,841 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-29 11:41:18,031 epoch 1 - iter 35/357 - loss 7.75004229 - samples/sec: 216.38\n",
            "2020-04-29 11:41:22,024 epoch 1 - iter 70/357 - loss 7.06569052 - samples/sec: 281.96\n",
            "2020-04-29 11:41:26,578 epoch 1 - iter 105/357 - loss 6.50798885 - samples/sec: 247.09\n",
            "2020-04-29 11:41:30,885 epoch 1 - iter 140/357 - loss 6.09738637 - samples/sec: 261.23\n",
            "2020-04-29 11:41:35,467 epoch 1 - iter 175/357 - loss 5.81895655 - samples/sec: 245.71\n",
            "2020-04-29 11:41:39,889 epoch 1 - iter 210/357 - loss 5.53458138 - samples/sec: 254.49\n",
            "2020-04-29 11:41:44,525 epoch 1 - iter 245/357 - loss 5.31994035 - samples/sec: 242.59\n",
            "2020-04-29 11:41:48,703 epoch 1 - iter 280/357 - loss 5.12053878 - samples/sec: 269.69\n",
            "2020-04-29 11:41:53,434 epoch 1 - iter 315/357 - loss 4.98514322 - samples/sec: 238.22\n",
            "2020-04-29 11:41:57,733 epoch 1 - iter 350/357 - loss 4.85167450 - samples/sec: 261.62\n",
            "2020-04-29 11:41:58,690 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:41:58,692 EPOCH 1 done: loss 4.8152 - lr 0.1000\n",
            "2020-04-29 11:42:05,318 DEV : loss 2.782531261444092 - score 0.4507\n",
            "2020-04-29 11:42:44,766 TEST : loss 3.108873128890991 - score 0.4589\n",
            "2020-04-29 11:42:44,886 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:42:48,400 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:42:52,628 epoch 2 - iter 35/357 - loss 3.52856533 - samples/sec: 265.19\n",
            "2020-04-29 11:42:56,750 epoch 2 - iter 70/357 - loss 3.55103650 - samples/sec: 273.22\n",
            "2020-04-29 11:43:01,092 epoch 2 - iter 105/357 - loss 3.48242185 - samples/sec: 259.41\n",
            "2020-04-29 11:43:05,691 epoch 2 - iter 140/357 - loss 3.51562074 - samples/sec: 244.62\n",
            "2020-04-29 11:43:09,764 epoch 2 - iter 175/357 - loss 3.41721987 - samples/sec: 276.45\n",
            "2020-04-29 11:43:14,591 epoch 2 - iter 210/357 - loss 3.37550157 - samples/sec: 233.19\n",
            "2020-04-29 11:43:18,678 epoch 2 - iter 245/357 - loss 3.33105640 - samples/sec: 275.55\n",
            "2020-04-29 11:43:23,083 epoch 2 - iter 280/357 - loss 3.28431003 - samples/sec: 255.54\n",
            "2020-04-29 11:43:27,633 epoch 2 - iter 315/357 - loss 3.25881732 - samples/sec: 247.44\n",
            "2020-04-29 11:43:31,982 epoch 2 - iter 350/357 - loss 3.21638159 - samples/sec: 258.73\n",
            "2020-04-29 11:43:33,131 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:43:33,133 EPOCH 2 done: loss 3.2230 - lr 0.1000\n",
            "2020-04-29 11:43:39,317 DEV : loss 2.3153750896453857 - score 0.5225\n",
            "2020-04-29 11:44:16,232 TEST : loss 2.5965912342071533 - score 0.5331\n",
            "2020-04-29 11:44:16,377 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:44:19,551 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:44:23,973 epoch 3 - iter 35/357 - loss 3.33520828 - samples/sec: 253.59\n",
            "2020-04-29 11:44:28,451 epoch 3 - iter 70/357 - loss 3.19427920 - samples/sec: 251.41\n",
            "2020-04-29 11:44:33,095 epoch 3 - iter 105/357 - loss 3.07191492 - samples/sec: 242.22\n",
            "2020-04-29 11:44:37,465 epoch 3 - iter 140/357 - loss 3.08343548 - samples/sec: 257.76\n",
            "2020-04-29 11:44:41,656 epoch 3 - iter 175/357 - loss 3.03607556 - samples/sec: 268.62\n",
            "2020-04-29 11:44:46,259 epoch 3 - iter 210/357 - loss 2.98885942 - samples/sec: 244.59\n",
            "2020-04-29 11:44:50,315 epoch 3 - iter 245/357 - loss 2.92353362 - samples/sec: 277.44\n",
            "2020-04-29 11:44:54,481 epoch 3 - iter 280/357 - loss 2.91220125 - samples/sec: 270.34\n",
            "2020-04-29 11:44:59,260 epoch 3 - iter 315/357 - loss 2.89427851 - samples/sec: 235.38\n",
            "2020-04-29 11:45:03,253 epoch 3 - iter 350/357 - loss 2.87461279 - samples/sec: 281.99\n",
            "2020-04-29 11:45:04,103 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:45:04,104 EPOCH 3 done: loss 2.8701 - lr 0.1000\n",
            "2020-04-29 11:45:10,263 DEV : loss 2.050078868865967 - score 0.5618\n",
            "2020-04-29 11:45:49,197 TEST : loss 2.274139642715454 - score 0.5782\n",
            "2020-04-29 11:45:49,325 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:45:52,540 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:45:56,906 epoch 4 - iter 35/357 - loss 2.63219496 - samples/sec: 256.95\n",
            "2020-04-29 11:46:01,096 epoch 4 - iter 70/357 - loss 2.64026656 - samples/sec: 268.60\n",
            "2020-04-29 11:46:05,415 epoch 4 - iter 105/357 - loss 2.67315489 - samples/sec: 260.63\n",
            "2020-04-29 11:46:09,607 epoch 4 - iter 140/357 - loss 2.64775957 - samples/sec: 268.57\n",
            "2020-04-29 11:46:14,051 epoch 4 - iter 175/357 - loss 2.71528163 - samples/sec: 253.18\n",
            "2020-04-29 11:46:18,604 epoch 4 - iter 210/357 - loss 2.70182171 - samples/sec: 247.33\n",
            "2020-04-29 11:46:22,828 epoch 4 - iter 245/357 - loss 2.69692981 - samples/sec: 266.42\n",
            "2020-04-29 11:46:27,281 epoch 4 - iter 280/357 - loss 2.68362453 - samples/sec: 252.80\n",
            "2020-04-29 11:46:31,596 epoch 4 - iter 315/357 - loss 2.70147964 - samples/sec: 260.76\n",
            "2020-04-29 11:46:36,163 epoch 4 - iter 350/357 - loss 2.71540382 - samples/sec: 246.47\n",
            "2020-04-29 11:46:37,007 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:46:37,008 EPOCH 4 done: loss 2.7092 - lr 0.1000\n",
            "2020-04-29 11:46:43,259 DEV : loss 1.9108664989471436 - score 0.5856\n",
            "2020-04-29 11:47:18,975 TEST : loss 2.151308059692383 - score 0.5976\n",
            "2020-04-29 11:47:19,110 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:47:22,301 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:47:26,553 epoch 5 - iter 35/357 - loss 2.56750939 - samples/sec: 263.88\n",
            "2020-04-29 11:47:31,137 epoch 5 - iter 70/357 - loss 2.52059156 - samples/sec: 245.47\n",
            "2020-04-29 11:47:35,352 epoch 5 - iter 105/357 - loss 2.52604985 - samples/sec: 267.19\n",
            "2020-04-29 11:47:39,806 epoch 5 - iter 140/357 - loss 2.57710072 - samples/sec: 252.76\n",
            "2020-04-29 11:47:44,164 epoch 5 - iter 175/357 - loss 2.55842494 - samples/sec: 258.21\n",
            "2020-04-29 11:47:48,590 epoch 5 - iter 210/357 - loss 2.56874612 - samples/sec: 254.53\n",
            "2020-04-29 11:47:52,642 epoch 5 - iter 245/357 - loss 2.56883426 - samples/sec: 277.86\n",
            "2020-04-29 11:47:57,184 epoch 5 - iter 280/357 - loss 2.57726200 - samples/sec: 248.40\n",
            "2020-04-29 11:48:01,453 epoch 5 - iter 315/357 - loss 2.56646106 - samples/sec: 263.58\n",
            "2020-04-29 11:48:06,241 epoch 5 - iter 350/357 - loss 2.56664713 - samples/sec: 235.04\n",
            "2020-04-29 11:48:07,066 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:48:07,070 EPOCH 5 done: loss 2.5580 - lr 0.1000\n",
            "2020-04-29 11:48:13,534 DEV : loss 1.9560788869857788 - score 0.5904\n",
            "2020-04-29 11:48:50,087 TEST : loss 2.1947319507598877 - score 0.6056\n",
            "2020-04-29 11:48:50,211 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:48:53,430 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:48:57,533 epoch 6 - iter 35/357 - loss 2.44619074 - samples/sec: 273.35\n",
            "2020-04-29 11:49:01,915 epoch 6 - iter 70/357 - loss 2.53741948 - samples/sec: 256.81\n",
            "2020-04-29 11:49:06,470 epoch 6 - iter 105/357 - loss 2.57248973 - samples/sec: 246.88\n",
            "2020-04-29 11:49:11,245 epoch 6 - iter 140/357 - loss 2.52921163 - samples/sec: 235.74\n",
            "2020-04-29 11:49:15,518 epoch 6 - iter 175/357 - loss 2.55522308 - samples/sec: 263.77\n",
            "2020-04-29 11:49:19,800 epoch 6 - iter 210/357 - loss 2.54675296 - samples/sec: 262.90\n",
            "2020-04-29 11:49:23,767 epoch 6 - iter 245/357 - loss 2.49689501 - samples/sec: 283.88\n",
            "2020-04-29 11:49:28,381 epoch 6 - iter 280/357 - loss 2.51086881 - samples/sec: 243.82\n",
            "2020-04-29 11:49:32,678 epoch 6 - iter 315/357 - loss 2.50730324 - samples/sec: 261.93\n",
            "2020-04-29 11:49:36,713 epoch 6 - iter 350/357 - loss 2.48519966 - samples/sec: 279.34\n",
            "2020-04-29 11:49:37,545 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:49:37,546 EPOCH 6 done: loss 2.4803 - lr 0.1000\n",
            "2020-04-29 11:49:44,211 DEV : loss 1.665930151939392 - score 0.6424\n",
            "2020-04-29 11:50:21,883 TEST : loss 1.8941998481750488 - score 0.6465\n",
            "2020-04-29 11:50:22,017 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:50:25,269 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:50:29,726 epoch 7 - iter 35/357 - loss 2.48651690 - samples/sec: 251.60\n",
            "2020-04-29 11:50:34,469 epoch 7 - iter 70/357 - loss 2.54777668 - samples/sec: 237.22\n",
            "2020-04-29 11:50:38,569 epoch 7 - iter 105/357 - loss 2.50187983 - samples/sec: 274.62\n",
            "2020-04-29 11:50:42,658 epoch 7 - iter 140/357 - loss 2.43092486 - samples/sec: 275.40\n",
            "2020-04-29 11:50:46,814 epoch 7 - iter 175/357 - loss 2.43202975 - samples/sec: 271.03\n",
            "2020-04-29 11:50:51,464 epoch 7 - iter 210/357 - loss 2.40218018 - samples/sec: 241.86\n",
            "2020-04-29 11:50:55,571 epoch 7 - iter 245/357 - loss 2.40611783 - samples/sec: 274.06\n",
            "2020-04-29 11:50:59,746 epoch 7 - iter 280/357 - loss 2.40009820 - samples/sec: 269.70\n",
            "2020-04-29 11:51:04,613 epoch 7 - iter 315/357 - loss 2.40611206 - samples/sec: 231.08\n",
            "2020-04-29 11:51:09,355 epoch 7 - iter 350/357 - loss 2.39315686 - samples/sec: 237.43\n",
            "2020-04-29 11:51:10,178 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:51:10,180 EPOCH 7 done: loss 2.3840 - lr 0.1000\n",
            "2020-04-29 11:51:16,902 DEV : loss 1.6093436479568481 - score 0.6487\n",
            "2020-04-29 11:51:53,242 TEST : loss 1.837760329246521 - score 0.6505\n",
            "2020-04-29 11:51:53,367 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:51:56,533 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:52:00,840 epoch 8 - iter 35/357 - loss 2.32386585 - samples/sec: 260.38\n",
            "2020-04-29 11:52:05,523 epoch 8 - iter 70/357 - loss 2.38126420 - samples/sec: 240.34\n",
            "2020-04-29 11:52:10,260 epoch 8 - iter 105/357 - loss 2.35533606 - samples/sec: 237.47\n",
            "2020-04-29 11:52:14,583 epoch 8 - iter 140/357 - loss 2.37045325 - samples/sec: 260.60\n",
            "2020-04-29 11:52:18,997 epoch 8 - iter 175/357 - loss 2.34459468 - samples/sec: 254.87\n",
            "2020-04-29 11:52:23,559 epoch 8 - iter 210/357 - loss 2.33481192 - samples/sec: 246.60\n",
            "2020-04-29 11:52:27,867 epoch 8 - iter 245/357 - loss 2.32461973 - samples/sec: 261.29\n",
            "2020-04-29 11:52:31,888 epoch 8 - iter 280/357 - loss 2.29172029 - samples/sec: 279.87\n",
            "2020-04-29 11:52:36,200 epoch 8 - iter 315/357 - loss 2.31136192 - samples/sec: 260.93\n",
            "2020-04-29 11:52:40,227 epoch 8 - iter 350/357 - loss 2.30543496 - samples/sec: 279.82\n",
            "2020-04-29 11:52:41,013 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:52:41,014 EPOCH 8 done: loss 2.3087 - lr 0.1000\n",
            "2020-04-29 11:52:47,386 DEV : loss 1.5244150161743164 - score 0.6669\n",
            "2020-04-29 11:53:25,220 TEST : loss 1.7347878217697144 - score 0.6725\n",
            "2020-04-29 11:53:25,342 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:53:28,512 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:53:33,237 epoch 9 - iter 35/357 - loss 2.27238849 - samples/sec: 237.44\n",
            "2020-04-29 11:53:37,779 epoch 9 - iter 70/357 - loss 2.18267441 - samples/sec: 247.99\n",
            "2020-04-29 11:53:42,023 epoch 9 - iter 105/357 - loss 2.26156792 - samples/sec: 265.33\n",
            "2020-04-29 11:53:46,114 epoch 9 - iter 140/357 - loss 2.25021792 - samples/sec: 275.28\n",
            "2020-04-29 11:53:50,134 epoch 9 - iter 175/357 - loss 2.25058553 - samples/sec: 280.02\n",
            "2020-04-29 11:53:54,405 epoch 9 - iter 210/357 - loss 2.25422126 - samples/sec: 263.46\n",
            "2020-04-29 11:53:58,881 epoch 9 - iter 245/357 - loss 2.24911851 - samples/sec: 251.58\n",
            "2020-04-29 11:54:03,247 epoch 9 - iter 280/357 - loss 2.24182436 - samples/sec: 258.09\n",
            "2020-04-29 11:54:07,483 epoch 9 - iter 315/357 - loss 2.24129671 - samples/sec: 265.64\n",
            "2020-04-29 11:54:11,634 epoch 9 - iter 350/357 - loss 2.22862052 - samples/sec: 271.23\n",
            "2020-04-29 11:54:13,009 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:54:13,011 EPOCH 9 done: loss 2.2312 - lr 0.1000\n",
            "2020-04-29 11:54:19,485 DEV : loss 1.4785633087158203 - score 0.6727\n",
            "2020-04-29 11:54:56,308 TEST : loss 1.7078063488006592 - score 0.6714\n",
            "2020-04-29 11:54:56,439 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:54:59,604 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:55:03,966 epoch 10 - iter 35/357 - loss 2.15965948 - samples/sec: 257.10\n",
            "2020-04-29 11:55:07,921 epoch 10 - iter 70/357 - loss 2.20565542 - samples/sec: 284.75\n",
            "2020-04-29 11:55:11,853 epoch 10 - iter 105/357 - loss 2.17720741 - samples/sec: 286.40\n",
            "2020-04-29 11:55:16,660 epoch 10 - iter 140/357 - loss 2.20178156 - samples/sec: 234.12\n",
            "2020-04-29 11:55:20,886 epoch 10 - iter 175/357 - loss 2.19014069 - samples/sec: 266.55\n",
            "2020-04-29 11:55:25,720 epoch 10 - iter 210/357 - loss 2.22112810 - samples/sec: 232.83\n",
            "2020-04-29 11:55:30,113 epoch 10 - iter 245/357 - loss 2.22166377 - samples/sec: 256.16\n",
            "2020-04-29 11:55:34,415 epoch 10 - iter 280/357 - loss 2.20104551 - samples/sec: 261.69\n",
            "2020-04-29 11:55:38,657 epoch 10 - iter 315/357 - loss 2.19419157 - samples/sec: 265.38\n",
            "2020-04-29 11:55:42,916 epoch 10 - iter 350/357 - loss 2.18383599 - samples/sec: 264.37\n",
            "2020-04-29 11:55:43,823 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:55:43,824 EPOCH 10 done: loss 2.1810 - lr 0.1000\n",
            "2020-04-29 11:55:50,097 DEV : loss 1.4823952913284302 - score 0.6708\n",
            "2020-04-29 11:56:26,502 TEST : loss 1.7061790227890015 - score 0.6805\n",
            "2020-04-29 11:56:26,625 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 11:56:26,627 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:56:30,758 epoch 11 - iter 35/357 - loss 2.23397162 - samples/sec: 271.47\n",
            "2020-04-29 11:56:34,855 epoch 11 - iter 70/357 - loss 2.13527669 - samples/sec: 274.74\n",
            "2020-04-29 11:56:39,281 epoch 11 - iter 105/357 - loss 2.24541597 - samples/sec: 254.21\n",
            "2020-04-29 11:56:43,912 epoch 11 - iter 140/357 - loss 2.22349469 - samples/sec: 242.94\n",
            "2020-04-29 11:56:48,328 epoch 11 - iter 175/357 - loss 2.17807091 - samples/sec: 254.89\n",
            "2020-04-29 11:56:52,243 epoch 11 - iter 210/357 - loss 2.16052202 - samples/sec: 287.71\n",
            "2020-04-29 11:56:56,426 epoch 11 - iter 245/357 - loss 2.15659842 - samples/sec: 269.29\n",
            "2020-04-29 11:57:00,283 epoch 11 - iter 280/357 - loss 2.12763438 - samples/sec: 292.01\n",
            "2020-04-29 11:57:04,695 epoch 11 - iter 315/357 - loss 2.13534244 - samples/sec: 255.51\n",
            "2020-04-29 11:57:09,099 epoch 11 - iter 350/357 - loss 2.13778822 - samples/sec: 255.46\n",
            "2020-04-29 11:57:09,903 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:57:09,904 EPOCH 11 done: loss 2.1418 - lr 0.1000\n",
            "2020-04-29 11:57:16,298 DEV : loss 1.42577064037323 - score 0.6834\n",
            "2020-04-29 11:57:54,516 TEST : loss 1.664438247680664 - score 0.6791\n",
            "2020-04-29 11:57:54,641 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:57:57,741 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:58:01,882 epoch 12 - iter 35/357 - loss 2.17365797 - samples/sec: 270.77\n",
            "2020-04-29 11:58:06,091 epoch 12 - iter 70/357 - loss 2.14769111 - samples/sec: 267.94\n",
            "2020-04-29 11:58:10,213 epoch 12 - iter 105/357 - loss 2.05321180 - samples/sec: 273.37\n",
            "2020-04-29 11:58:14,383 epoch 12 - iter 140/357 - loss 2.08349735 - samples/sec: 270.16\n",
            "2020-04-29 11:58:18,312 epoch 12 - iter 175/357 - loss 2.05078791 - samples/sec: 286.48\n",
            "2020-04-29 11:58:22,604 epoch 12 - iter 210/357 - loss 2.07089127 - samples/sec: 262.33\n",
            "2020-04-29 11:58:27,176 epoch 12 - iter 245/357 - loss 2.08158321 - samples/sec: 246.37\n",
            "2020-04-29 11:58:31,189 epoch 12 - iter 280/357 - loss 2.07145773 - samples/sec: 280.55\n",
            "2020-04-29 11:58:35,742 epoch 12 - iter 315/357 - loss 2.09656673 - samples/sec: 247.03\n",
            "2020-04-29 11:58:40,215 epoch 12 - iter 350/357 - loss 2.08813875 - samples/sec: 251.53\n",
            "2020-04-29 11:58:41,083 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:58:41,085 EPOCH 12 done: loss 2.0784 - lr 0.1000\n",
            "2020-04-29 11:58:47,739 DEV : loss 1.3319708108901978 - score 0.7046\n",
            "2020-04-29 11:59:23,735 TEST : loss 1.562941074371338 - score 0.6949\n",
            "2020-04-29 11:59:23,866 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 11:59:27,006 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 11:59:31,557 epoch 13 - iter 35/357 - loss 2.01126248 - samples/sec: 246.37\n",
            "2020-04-29 11:59:35,780 epoch 13 - iter 70/357 - loss 2.00066358 - samples/sec: 266.36\n",
            "2020-04-29 11:59:40,024 epoch 13 - iter 105/357 - loss 2.07348739 - samples/sec: 265.11\n",
            "2020-04-29 11:59:44,114 epoch 13 - iter 140/357 - loss 2.00381334 - samples/sec: 275.28\n",
            "2020-04-29 11:59:48,581 epoch 13 - iter 175/357 - loss 2.00646174 - samples/sec: 251.98\n",
            "2020-04-29 11:59:52,767 epoch 13 - iter 210/357 - loss 2.00238621 - samples/sec: 268.94\n",
            "2020-04-29 11:59:57,424 epoch 13 - iter 245/357 - loss 2.00842869 - samples/sec: 241.80\n",
            "2020-04-29 12:00:01,642 epoch 13 - iter 280/357 - loss 2.00399608 - samples/sec: 266.76\n",
            "2020-04-29 12:00:05,623 epoch 13 - iter 315/357 - loss 2.01189450 - samples/sec: 282.95\n",
            "2020-04-29 12:00:10,301 epoch 13 - iter 350/357 - loss 2.02316682 - samples/sec: 240.46\n",
            "2020-04-29 12:00:11,277 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:00:11,279 EPOCH 13 done: loss 2.0344 - lr 0.1000\n",
            "2020-04-29 12:00:17,899 DEV : loss 1.4112968444824219 - score 0.6955\n",
            "2020-04-29 12:00:53,970 TEST : loss 1.6287317276000977 - score 0.6961\n",
            "2020-04-29 12:00:54,102 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 12:00:54,103 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:00:58,348 epoch 14 - iter 35/357 - loss 1.92110209 - samples/sec: 264.30\n",
            "2020-04-29 12:01:02,552 epoch 14 - iter 70/357 - loss 1.95731307 - samples/sec: 267.72\n",
            "2020-04-29 12:01:06,665 epoch 14 - iter 105/357 - loss 1.96970238 - samples/sec: 273.82\n",
            "2020-04-29 12:01:11,138 epoch 14 - iter 140/357 - loss 2.00733225 - samples/sec: 251.55\n",
            "2020-04-29 12:01:15,652 epoch 14 - iter 175/357 - loss 2.02305614 - samples/sec: 249.13\n",
            "2020-04-29 12:01:19,863 epoch 14 - iter 210/357 - loss 2.02822194 - samples/sec: 267.47\n",
            "2020-04-29 12:01:24,147 epoch 14 - iter 245/357 - loss 2.01755207 - samples/sec: 262.67\n",
            "2020-04-29 12:01:28,789 epoch 14 - iter 280/357 - loss 2.02210270 - samples/sec: 242.42\n",
            "2020-04-29 12:01:32,974 epoch 14 - iter 315/357 - loss 2.01858901 - samples/sec: 269.02\n",
            "2020-04-29 12:01:37,154 epoch 14 - iter 350/357 - loss 2.01589791 - samples/sec: 269.25\n",
            "2020-04-29 12:01:38,195 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:01:38,196 EPOCH 14 done: loss 2.0224 - lr 0.1000\n",
            "2020-04-29 12:01:44,534 DEV : loss 1.3017925024032593 - score 0.716\n",
            "2020-04-29 12:02:22,725 TEST : loss 1.4986861944198608 - score 0.7145\n",
            "2020-04-29 12:02:22,849 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:02:26,138 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:02:30,591 epoch 15 - iter 35/357 - loss 1.99342146 - samples/sec: 251.79\n",
            "2020-04-29 12:02:35,122 epoch 15 - iter 70/357 - loss 2.16030959 - samples/sec: 248.35\n",
            "2020-04-29 12:02:39,535 epoch 15 - iter 105/357 - loss 2.03959647 - samples/sec: 255.30\n",
            "2020-04-29 12:02:44,062 epoch 15 - iter 140/357 - loss 2.01840228 - samples/sec: 248.53\n",
            "2020-04-29 12:02:48,255 epoch 15 - iter 175/357 - loss 1.98910935 - samples/sec: 268.45\n",
            "2020-04-29 12:02:52,427 epoch 15 - iter 210/357 - loss 1.97590236 - samples/sec: 269.93\n",
            "2020-04-29 12:02:56,651 epoch 15 - iter 245/357 - loss 1.98221537 - samples/sec: 266.57\n",
            "2020-04-29 12:03:01,701 epoch 15 - iter 280/357 - loss 1.97217534 - samples/sec: 222.59\n",
            "2020-04-29 12:03:06,193 epoch 15 - iter 315/357 - loss 1.99040082 - samples/sec: 250.49\n",
            "2020-04-29 12:03:10,220 epoch 15 - iter 350/357 - loss 1.99012251 - samples/sec: 279.67\n",
            "2020-04-29 12:03:11,102 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:03:11,104 EPOCH 15 done: loss 1.9968 - lr 0.1000\n",
            "2020-04-29 12:03:17,754 DEV : loss 1.3332618474960327 - score 0.7114\n",
            "2020-04-29 12:03:54,322 TEST : loss 1.5437835454940796 - score 0.7133\n",
            "2020-04-29 12:03:54,452 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 12:03:54,454 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:03:58,628 epoch 16 - iter 35/357 - loss 1.81872716 - samples/sec: 268.68\n",
            "2020-04-29 12:04:03,336 epoch 16 - iter 70/357 - loss 1.81625391 - samples/sec: 238.91\n",
            "2020-04-29 12:04:07,504 epoch 16 - iter 105/357 - loss 1.87883748 - samples/sec: 269.95\n",
            "2020-04-29 12:04:11,818 epoch 16 - iter 140/357 - loss 1.93845966 - samples/sec: 260.80\n",
            "2020-04-29 12:04:15,975 epoch 16 - iter 175/357 - loss 1.92464561 - samples/sec: 270.85\n",
            "2020-04-29 12:04:20,380 epoch 16 - iter 210/357 - loss 1.94381524 - samples/sec: 255.68\n",
            "2020-04-29 12:04:24,337 epoch 16 - iter 245/357 - loss 1.92459879 - samples/sec: 284.57\n",
            "2020-04-29 12:04:28,423 epoch 16 - iter 280/357 - loss 1.93436682 - samples/sec: 275.40\n",
            "2020-04-29 12:04:32,925 epoch 16 - iter 315/357 - loss 1.92845523 - samples/sec: 250.04\n",
            "2020-04-29 12:04:37,557 epoch 16 - iter 350/357 - loss 1.95120467 - samples/sec: 243.25\n",
            "2020-04-29 12:04:38,416 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:04:38,417 EPOCH 16 done: loss 1.9557 - lr 0.1000\n",
            "2020-04-29 12:04:44,737 DEV : loss 1.312354564666748 - score 0.7122\n",
            "2020-04-29 12:05:23,051 TEST : loss 1.5113801956176758 - score 0.7159\n",
            "2020-04-29 12:05:23,176 BAD EPOCHS (no improvement): 2\n",
            "2020-04-29 12:05:23,177 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:05:27,229 epoch 17 - iter 35/357 - loss 1.77746576 - samples/sec: 276.93\n",
            "2020-04-29 12:05:31,581 epoch 17 - iter 70/357 - loss 1.83874733 - samples/sec: 258.70\n",
            "2020-04-29 12:05:36,267 epoch 17 - iter 105/357 - loss 1.90833590 - samples/sec: 239.99\n",
            "2020-04-29 12:05:40,310 epoch 17 - iter 140/357 - loss 1.92375938 - samples/sec: 278.58\n",
            "2020-04-29 12:05:44,755 epoch 17 - iter 175/357 - loss 1.91964320 - samples/sec: 253.13\n",
            "2020-04-29 12:05:48,892 epoch 17 - iter 210/357 - loss 1.91093933 - samples/sec: 272.24\n",
            "2020-04-29 12:05:53,476 epoch 17 - iter 245/357 - loss 1.88093661 - samples/sec: 245.54\n",
            "2020-04-29 12:05:57,917 epoch 17 - iter 280/357 - loss 1.89093982 - samples/sec: 253.54\n",
            "2020-04-29 12:06:01,996 epoch 17 - iter 315/357 - loss 1.90107203 - samples/sec: 276.03\n",
            "2020-04-29 12:06:06,290 epoch 17 - iter 350/357 - loss 1.89666626 - samples/sec: 262.22\n",
            "2020-04-29 12:06:07,091 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:06:07,092 EPOCH 17 done: loss 1.9022 - lr 0.1000\n",
            "2020-04-29 12:06:13,585 DEV : loss 1.2759836912155151 - score 0.7224\n",
            "2020-04-29 12:06:50,552 TEST : loss 1.4744541645050049 - score 0.72\n",
            "2020-04-29 12:06:50,686 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:06:53,849 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:06:58,242 epoch 18 - iter 35/357 - loss 1.98118487 - samples/sec: 255.32\n",
            "2020-04-29 12:07:02,504 epoch 18 - iter 70/357 - loss 1.97250785 - samples/sec: 264.15\n",
            "2020-04-29 12:07:06,609 epoch 18 - iter 105/357 - loss 1.92815300 - samples/sec: 274.38\n",
            "2020-04-29 12:07:11,536 epoch 18 - iter 140/357 - loss 1.93493107 - samples/sec: 228.21\n",
            "2020-04-29 12:07:15,658 epoch 18 - iter 175/357 - loss 1.90256441 - samples/sec: 273.03\n",
            "2020-04-29 12:07:20,125 epoch 18 - iter 210/357 - loss 1.92092470 - samples/sec: 252.16\n",
            "2020-04-29 12:07:24,175 epoch 18 - iter 245/357 - loss 1.91666860 - samples/sec: 278.00\n",
            "2020-04-29 12:07:28,384 epoch 18 - iter 280/357 - loss 1.89342761 - samples/sec: 267.39\n",
            "2020-04-29 12:07:32,678 epoch 18 - iter 315/357 - loss 1.89042768 - samples/sec: 262.17\n",
            "2020-04-29 12:07:37,146 epoch 18 - iter 350/357 - loss 1.89412582 - samples/sec: 251.85\n",
            "2020-04-29 12:07:37,947 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:07:37,948 EPOCH 18 done: loss 1.8853 - lr 0.1000\n",
            "2020-04-29 12:07:44,780 DEV : loss 1.226337194442749 - score 0.7245\n",
            "2020-04-29 12:08:21,028 TEST : loss 1.431357741355896 - score 0.7217\n",
            "2020-04-29 12:08:21,174 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:08:24,365 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:08:29,217 epoch 19 - iter 35/357 - loss 1.81753706 - samples/sec: 231.05\n",
            "2020-04-29 12:08:33,486 epoch 19 - iter 70/357 - loss 1.82091873 - samples/sec: 263.67\n",
            "2020-04-29 12:08:37,760 epoch 19 - iter 105/357 - loss 1.82505145 - samples/sec: 263.21\n",
            "2020-04-29 12:08:42,179 epoch 19 - iter 140/357 - loss 1.84111681 - samples/sec: 254.62\n",
            "2020-04-29 12:08:46,580 epoch 19 - iter 175/357 - loss 1.83933604 - samples/sec: 255.83\n",
            "2020-04-29 12:08:51,379 epoch 19 - iter 210/357 - loss 1.86042900 - samples/sec: 234.48\n",
            "2020-04-29 12:08:55,664 epoch 19 - iter 245/357 - loss 1.85414046 - samples/sec: 262.67\n",
            "2020-04-29 12:08:59,890 epoch 19 - iter 280/357 - loss 1.85352019 - samples/sec: 266.19\n",
            "2020-04-29 12:09:04,021 epoch 19 - iter 315/357 - loss 1.84532275 - samples/sec: 272.40\n",
            "2020-04-29 12:09:07,985 epoch 19 - iter 350/357 - loss 1.85384379 - samples/sec: 284.09\n",
            "2020-04-29 12:09:08,761 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:09:08,764 EPOCH 19 done: loss 1.8557 - lr 0.1000\n",
            "2020-04-29 12:09:15,388 DEV : loss 1.1833784580230713 - score 0.7328\n",
            "2020-04-29 12:09:53,632 TEST : loss 1.3965377807617188 - score 0.7284\n",
            "2020-04-29 12:09:53,766 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:09:56,984 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:10:01,248 epoch 20 - iter 35/357 - loss 1.75245957 - samples/sec: 263.05\n",
            "2020-04-29 12:10:05,661 epoch 20 - iter 70/357 - loss 1.79813352 - samples/sec: 255.13\n",
            "2020-04-29 12:10:09,986 epoch 20 - iter 105/357 - loss 1.83590954 - samples/sec: 260.46\n",
            "2020-04-29 12:10:14,463 epoch 20 - iter 140/357 - loss 1.84991362 - samples/sec: 251.86\n",
            "2020-04-29 12:10:18,849 epoch 20 - iter 175/357 - loss 1.87929004 - samples/sec: 256.66\n",
            "2020-04-29 12:10:23,229 epoch 20 - iter 210/357 - loss 1.86990299 - samples/sec: 256.90\n",
            "2020-04-29 12:10:27,317 epoch 20 - iter 245/357 - loss 1.86710765 - samples/sec: 275.49\n",
            "2020-04-29 12:10:31,572 epoch 20 - iter 280/357 - loss 1.88212911 - samples/sec: 264.56\n",
            "2020-04-29 12:10:35,891 epoch 20 - iter 315/357 - loss 1.87427334 - samples/sec: 260.64\n",
            "2020-04-29 12:10:39,917 epoch 20 - iter 350/357 - loss 1.86580009 - samples/sec: 279.62\n",
            "2020-04-29 12:10:40,768 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:10:40,770 EPOCH 20 done: loss 1.8654 - lr 0.1000\n",
            "2020-04-29 12:10:47,018 DEV : loss 1.2294399738311768 - score 0.732\n",
            "2020-04-29 12:11:23,851 TEST : loss 1.4345695972442627 - score 0.7321\n",
            "2020-04-29 12:11:23,979 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 12:11:23,981 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:11:28,454 epoch 21 - iter 35/357 - loss 1.66250773 - samples/sec: 250.62\n",
            "2020-04-29 12:11:32,800 epoch 21 - iter 70/357 - loss 1.72047031 - samples/sec: 259.02\n",
            "2020-04-29 12:11:37,171 epoch 21 - iter 105/357 - loss 1.74922235 - samples/sec: 257.81\n",
            "2020-04-29 12:11:41,836 epoch 21 - iter 140/357 - loss 1.71841440 - samples/sec: 241.22\n",
            "2020-04-29 12:11:46,111 epoch 21 - iter 175/357 - loss 1.75479729 - samples/sec: 263.40\n",
            "2020-04-29 12:11:50,596 epoch 21 - iter 210/357 - loss 1.80787046 - samples/sec: 251.02\n",
            "2020-04-29 12:11:55,466 epoch 21 - iter 245/357 - loss 1.82269635 - samples/sec: 231.07\n",
            "2020-04-29 12:11:59,559 epoch 21 - iter 280/357 - loss 1.80855448 - samples/sec: 275.70\n",
            "2020-04-29 12:12:03,670 epoch 21 - iter 315/357 - loss 1.82339076 - samples/sec: 274.00\n",
            "2020-04-29 12:12:08,097 epoch 21 - iter 350/357 - loss 1.83743948 - samples/sec: 254.46\n",
            "2020-04-29 12:12:08,998 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:12:09,000 EPOCH 21 done: loss 1.8338 - lr 0.1000\n",
            "2020-04-29 12:12:15,450 DEV : loss 1.1906332969665527 - score 0.7383\n",
            "2020-04-29 12:12:52,451 TEST : loss 1.3949053287506104 - score 0.7349\n",
            "2020-04-29 12:12:52,583 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:12:55,864 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:13:00,270 epoch 22 - iter 35/357 - loss 1.83909829 - samples/sec: 254.49\n",
            "2020-04-29 12:13:04,617 epoch 22 - iter 70/357 - loss 1.81853070 - samples/sec: 258.93\n",
            "2020-04-29 12:13:08,788 epoch 22 - iter 105/357 - loss 1.72658749 - samples/sec: 269.95\n",
            "2020-04-29 12:13:13,081 epoch 22 - iter 140/357 - loss 1.70290350 - samples/sec: 262.30\n",
            "2020-04-29 12:13:18,247 epoch 22 - iter 175/357 - loss 1.76145873 - samples/sec: 217.69\n",
            "2020-04-29 12:13:22,572 epoch 22 - iter 210/357 - loss 1.77796811 - samples/sec: 260.58\n",
            "2020-04-29 12:13:26,647 epoch 22 - iter 245/357 - loss 1.78664618 - samples/sec: 276.31\n",
            "2020-04-29 12:13:30,987 epoch 22 - iter 280/357 - loss 1.78729994 - samples/sec: 259.37\n",
            "2020-04-29 12:13:35,515 epoch 22 - iter 315/357 - loss 1.79108534 - samples/sec: 248.66\n",
            "2020-04-29 12:13:39,919 epoch 22 - iter 350/357 - loss 1.80476843 - samples/sec: 255.99\n",
            "2020-04-29 12:13:40,685 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:13:40,686 EPOCH 22 done: loss 1.7987 - lr 0.1000\n",
            "2020-04-29 12:13:47,036 DEV : loss 1.1716095209121704 - score 0.7367\n",
            "2020-04-29 12:14:26,452 TEST : loss 1.3769128322601318 - score 0.735\n",
            "2020-04-29 12:14:26,575 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 12:14:26,577 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:14:30,606 epoch 23 - iter 35/357 - loss 1.60284365 - samples/sec: 278.45\n",
            "2020-04-29 12:14:34,869 epoch 23 - iter 70/357 - loss 1.68950222 - samples/sec: 264.03\n",
            "2020-04-29 12:14:39,507 epoch 23 - iter 105/357 - loss 1.71358122 - samples/sec: 242.66\n",
            "2020-04-29 12:14:44,020 epoch 23 - iter 140/357 - loss 1.74392979 - samples/sec: 249.39\n",
            "2020-04-29 12:14:47,996 epoch 23 - iter 175/357 - loss 1.72932444 - samples/sec: 283.70\n",
            "2020-04-29 12:14:52,368 epoch 23 - iter 210/357 - loss 1.77052147 - samples/sec: 257.75\n",
            "2020-04-29 12:14:56,737 epoch 23 - iter 245/357 - loss 1.76357233 - samples/sec: 257.73\n",
            "2020-04-29 12:15:01,044 epoch 23 - iter 280/357 - loss 1.75270951 - samples/sec: 261.43\n",
            "2020-04-29 12:15:05,387 epoch 23 - iter 315/357 - loss 1.76321911 - samples/sec: 259.28\n",
            "2020-04-29 12:15:09,694 epoch 23 - iter 350/357 - loss 1.77651831 - samples/sec: 261.40\n",
            "2020-04-29 12:15:10,638 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:15:10,641 EPOCH 23 done: loss 1.7709 - lr 0.1000\n",
            "2020-04-29 12:15:17,185 DEV : loss 1.1540296077728271 - score 0.7449\n",
            "2020-04-29 12:15:54,307 TEST : loss 1.3654435873031616 - score 0.7425\n",
            "2020-04-29 12:15:54,433 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:15:57,706 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:16:02,021 epoch 24 - iter 35/357 - loss 1.85153417 - samples/sec: 259.89\n",
            "2020-04-29 12:16:06,321 epoch 24 - iter 70/357 - loss 1.80291792 - samples/sec: 261.82\n",
            "2020-04-29 12:16:10,549 epoch 24 - iter 105/357 - loss 1.76954118 - samples/sec: 266.14\n",
            "2020-04-29 12:16:14,735 epoch 24 - iter 140/357 - loss 1.74114367 - samples/sec: 268.85\n",
            "2020-04-29 12:16:19,262 epoch 24 - iter 175/357 - loss 1.73581253 - samples/sec: 248.65\n",
            "2020-04-29 12:16:23,340 epoch 24 - iter 210/357 - loss 1.74357915 - samples/sec: 276.31\n",
            "2020-04-29 12:16:27,573 epoch 24 - iter 245/357 - loss 1.74215270 - samples/sec: 265.96\n",
            "2020-04-29 12:16:32,052 epoch 24 - iter 280/357 - loss 1.73334122 - samples/sec: 251.69\n",
            "2020-04-29 12:16:36,558 epoch 24 - iter 315/357 - loss 1.73230127 - samples/sec: 249.89\n",
            "2020-04-29 12:16:40,980 epoch 24 - iter 350/357 - loss 1.74328782 - samples/sec: 254.43\n",
            "2020-04-29 12:16:41,917 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:16:41,921 EPOCH 24 done: loss 1.7494 - lr 0.1000\n",
            "2020-04-29 12:16:48,225 DEV : loss 1.1255505084991455 - score 0.7493\n",
            "2020-04-29 12:17:25,098 TEST : loss 1.3394134044647217 - score 0.7437\n",
            "2020-04-29 12:17:25,222 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:17:28,470 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:17:32,866 epoch 25 - iter 35/357 - loss 1.70408273 - samples/sec: 255.49\n",
            "2020-04-29 12:17:37,346 epoch 25 - iter 70/357 - loss 1.77499849 - samples/sec: 251.47\n",
            "2020-04-29 12:17:41,693 epoch 25 - iter 105/357 - loss 1.77904865 - samples/sec: 258.86\n",
            "2020-04-29 12:17:46,388 epoch 25 - iter 140/357 - loss 1.75731971 - samples/sec: 239.58\n",
            "2020-04-29 12:17:50,559 epoch 25 - iter 175/357 - loss 1.71618950 - samples/sec: 270.03\n",
            "2020-04-29 12:17:54,791 epoch 25 - iter 210/357 - loss 1.76352834 - samples/sec: 266.01\n",
            "2020-04-29 12:17:59,103 epoch 25 - iter 245/357 - loss 1.74866123 - samples/sec: 261.18\n",
            "2020-04-29 12:18:03,671 epoch 25 - iter 280/357 - loss 1.74418445 - samples/sec: 246.35\n",
            "2020-04-29 12:18:07,760 epoch 25 - iter 315/357 - loss 1.74724669 - samples/sec: 275.42\n",
            "2020-04-29 12:18:12,592 epoch 25 - iter 350/357 - loss 1.74923028 - samples/sec: 233.07\n",
            "2020-04-29 12:18:13,373 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:18:13,375 EPOCH 25 done: loss 1.7576 - lr 0.1000\n",
            "2020-04-29 12:18:21,485 DEV : loss 1.1346487998962402 - score 0.747\n",
            "2020-04-29 12:18:57,797 TEST : loss 1.352502465248108 - score 0.7413\n",
            "2020-04-29 12:18:57,926 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 12:18:57,927 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:19:02,440 epoch 26 - iter 35/357 - loss 1.72709393 - samples/sec: 248.47\n",
            "2020-04-29 12:19:07,115 epoch 26 - iter 70/357 - loss 1.80455831 - samples/sec: 240.82\n",
            "2020-04-29 12:19:12,027 epoch 26 - iter 105/357 - loss 1.67757167 - samples/sec: 229.17\n",
            "2020-04-29 12:19:16,334 epoch 26 - iter 140/357 - loss 1.66594525 - samples/sec: 261.53\n",
            "2020-04-29 12:19:20,828 epoch 26 - iter 175/357 - loss 1.68797220 - samples/sec: 250.44\n",
            "2020-04-29 12:19:25,617 epoch 26 - iter 210/357 - loss 1.71252896 - samples/sec: 234.86\n",
            "2020-04-29 12:19:29,747 epoch 26 - iter 245/357 - loss 1.70989824 - samples/sec: 272.63\n",
            "2020-04-29 12:19:34,109 epoch 26 - iter 280/357 - loss 1.71921617 - samples/sec: 258.16\n",
            "2020-04-29 12:19:38,979 epoch 26 - iter 315/357 - loss 1.72727292 - samples/sec: 231.21\n",
            "2020-04-29 12:19:43,802 epoch 26 - iter 350/357 - loss 1.72328995 - samples/sec: 233.57\n",
            "2020-04-29 12:19:44,581 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:19:44,583 EPOCH 26 done: loss 1.7186 - lr 0.1000\n",
            "2020-04-29 12:19:51,383 DEV : loss 1.101264476776123 - score 0.7546\n",
            "2020-04-29 12:20:28,617 TEST : loss 1.3110241889953613 - score 0.7509\n",
            "2020-04-29 12:20:28,744 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:20:32,087 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:20:36,278 epoch 27 - iter 35/357 - loss 1.56088574 - samples/sec: 267.74\n",
            "2020-04-29 12:20:41,385 epoch 27 - iter 70/357 - loss 1.64755069 - samples/sec: 220.29\n",
            "2020-04-29 12:20:45,486 epoch 27 - iter 105/357 - loss 1.62452034 - samples/sec: 274.44\n",
            "2020-04-29 12:20:50,192 epoch 27 - iter 140/357 - loss 1.63637810 - samples/sec: 239.17\n",
            "2020-04-29 12:20:54,983 epoch 27 - iter 175/357 - loss 1.65246914 - samples/sec: 235.09\n",
            "2020-04-29 12:20:59,296 epoch 27 - iter 210/357 - loss 1.64863176 - samples/sec: 261.13\n",
            "2020-04-29 12:21:03,632 epoch 27 - iter 245/357 - loss 1.66521026 - samples/sec: 259.76\n",
            "2020-04-29 12:21:08,107 epoch 27 - iter 280/357 - loss 1.67123042 - samples/sec: 251.98\n",
            "2020-04-29 12:21:12,661 epoch 27 - iter 315/357 - loss 1.67357463 - samples/sec: 247.12\n",
            "2020-04-29 12:21:17,382 epoch 27 - iter 350/357 - loss 1.68126122 - samples/sec: 238.38\n",
            "2020-04-29 12:21:18,229 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:21:18,230 EPOCH 27 done: loss 1.6797 - lr 0.1000\n",
            "2020-04-29 12:21:24,804 DEV : loss 1.0832773447036743 - score 0.7562\n",
            "2020-04-29 12:22:04,399 TEST : loss 1.2848615646362305 - score 0.7523\n",
            "2020-04-29 12:22:04,523 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:22:07,912 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:22:12,313 epoch 28 - iter 35/357 - loss 1.74705622 - samples/sec: 254.79\n",
            "2020-04-29 12:22:16,947 epoch 28 - iter 70/357 - loss 1.75813021 - samples/sec: 243.01\n",
            "2020-04-29 12:22:21,609 epoch 28 - iter 105/357 - loss 1.74495216 - samples/sec: 242.09\n",
            "2020-04-29 12:22:26,076 epoch 28 - iter 140/357 - loss 1.72993053 - samples/sec: 252.10\n",
            "2020-04-29 12:22:31,017 epoch 28 - iter 175/357 - loss 1.72568618 - samples/sec: 227.87\n",
            "2020-04-29 12:22:35,240 epoch 28 - iter 210/357 - loss 1.71191918 - samples/sec: 266.74\n",
            "2020-04-29 12:22:40,392 epoch 28 - iter 245/357 - loss 1.72716329 - samples/sec: 218.72\n",
            "2020-04-29 12:22:44,843 epoch 28 - iter 280/357 - loss 1.71820052 - samples/sec: 252.97\n",
            "2020-04-29 12:22:49,452 epoch 28 - iter 315/357 - loss 1.70967759 - samples/sec: 244.32\n",
            "2020-04-29 12:22:54,212 epoch 28 - iter 350/357 - loss 1.70691365 - samples/sec: 236.52\n",
            "2020-04-29 12:22:55,060 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:22:55,061 EPOCH 28 done: loss 1.7101 - lr 0.1000\n",
            "2020-04-29 12:23:01,667 DEV : loss 1.2149590253829956 - score 0.74\n",
            "2020-04-29 12:23:40,263 TEST : loss 1.4404445886611938 - score 0.7339\n",
            "2020-04-29 12:23:40,400 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 12:23:40,401 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:23:44,998 epoch 29 - iter 35/357 - loss 1.66498304 - samples/sec: 244.11\n",
            "2020-04-29 12:23:49,774 epoch 29 - iter 70/357 - loss 1.72612179 - samples/sec: 235.59\n",
            "2020-04-29 12:23:54,376 epoch 29 - iter 105/357 - loss 1.71011441 - samples/sec: 244.68\n",
            "2020-04-29 12:23:58,704 epoch 29 - iter 140/357 - loss 1.71894524 - samples/sec: 260.28\n",
            "2020-04-29 12:24:03,070 epoch 29 - iter 175/357 - loss 1.72047691 - samples/sec: 257.89\n",
            "2020-04-29 12:24:07,966 epoch 29 - iter 210/357 - loss 1.71563795 - samples/sec: 229.85\n",
            "2020-04-29 12:24:12,411 epoch 29 - iter 245/357 - loss 1.69804883 - samples/sec: 253.42\n",
            "2020-04-29 12:24:16,999 epoch 29 - iter 280/357 - loss 1.68808569 - samples/sec: 245.35\n",
            "2020-04-29 12:24:21,702 epoch 29 - iter 315/357 - loss 1.68804256 - samples/sec: 239.40\n",
            "2020-04-29 12:24:26,384 epoch 29 - iter 350/357 - loss 1.68218975 - samples/sec: 240.42\n",
            "2020-04-29 12:24:27,111 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:24:27,115 EPOCH 29 done: loss 1.6757 - lr 0.1000\n",
            "2020-04-29 12:24:33,942 DEV : loss 1.1035008430480957 - score 0.755\n",
            "2020-04-29 12:25:11,797 TEST : loss 1.3096847534179688 - score 0.7552\n",
            "2020-04-29 12:25:11,944 BAD EPOCHS (no improvement): 2\n",
            "2020-04-29 12:25:11,945 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:25:16,170 epoch 30 - iter 35/357 - loss 1.74047407 - samples/sec: 265.45\n",
            "2020-04-29 12:25:20,683 epoch 30 - iter 70/357 - loss 1.68776236 - samples/sec: 249.52\n",
            "2020-04-29 12:25:25,099 epoch 30 - iter 105/357 - loss 1.64350374 - samples/sec: 255.19\n",
            "2020-04-29 12:25:29,714 epoch 30 - iter 140/357 - loss 1.65430773 - samples/sec: 243.95\n",
            "2020-04-29 12:25:34,162 epoch 30 - iter 175/357 - loss 1.65148271 - samples/sec: 253.00\n",
            "2020-04-29 12:25:38,835 epoch 30 - iter 210/357 - loss 1.64564007 - samples/sec: 240.83\n",
            "2020-04-29 12:25:43,074 epoch 30 - iter 245/357 - loss 1.65907189 - samples/sec: 265.86\n",
            "2020-04-29 12:25:47,806 epoch 30 - iter 280/357 - loss 1.66790285 - samples/sec: 237.72\n",
            "2020-04-29 12:25:52,287 epoch 30 - iter 315/357 - loss 1.66990900 - samples/sec: 251.20\n",
            "2020-04-29 12:25:56,669 epoch 30 - iter 350/357 - loss 1.66539141 - samples/sec: 256.96\n",
            "2020-04-29 12:25:57,537 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:25:57,539 EPOCH 30 done: loss 1.6648 - lr 0.1000\n",
            "2020-04-29 12:26:04,373 DEV : loss 1.084133505821228 - score 0.7555\n",
            "2020-04-29 12:26:44,282 TEST : loss 1.3157726526260376 - score 0.7496\n",
            "2020-04-29 12:26:44,409 BAD EPOCHS (no improvement): 3\n",
            "2020-04-29 12:26:44,411 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:26:48,671 epoch 31 - iter 35/357 - loss 1.48569637 - samples/sec: 263.25\n",
            "2020-04-29 12:26:53,195 epoch 31 - iter 70/357 - loss 1.65557126 - samples/sec: 249.02\n",
            "2020-04-29 12:26:57,708 epoch 31 - iter 105/357 - loss 1.65793351 - samples/sec: 249.46\n",
            "2020-04-29 12:27:02,103 epoch 31 - iter 140/357 - loss 1.68067431 - samples/sec: 256.42\n",
            "2020-04-29 12:27:06,346 epoch 31 - iter 175/357 - loss 1.65168642 - samples/sec: 265.46\n",
            "2020-04-29 12:27:10,880 epoch 31 - iter 210/357 - loss 1.66001795 - samples/sec: 248.33\n",
            "2020-04-29 12:27:15,210 epoch 31 - iter 245/357 - loss 1.64514091 - samples/sec: 260.11\n",
            "2020-04-29 12:27:19,838 epoch 31 - iter 280/357 - loss 1.63372324 - samples/sec: 243.14\n",
            "2020-04-29 12:27:24,273 epoch 31 - iter 315/357 - loss 1.64004597 - samples/sec: 253.97\n",
            "2020-04-29 12:27:28,575 epoch 31 - iter 350/357 - loss 1.64008323 - samples/sec: 261.77\n",
            "2020-04-29 12:27:29,436 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:27:29,437 EPOCH 31 done: loss 1.6365 - lr 0.1000\n",
            "2020-04-29 12:27:36,468 DEV : loss 1.0815575122833252 - score 0.7603\n",
            "2020-04-29 12:28:13,827 TEST : loss 1.2859382629394531 - score 0.7602\n",
            "2020-04-29 12:28:13,972 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:28:17,276 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:28:22,264 epoch 32 - iter 35/357 - loss 1.61867902 - samples/sec: 224.80\n",
            "2020-04-29 12:28:26,513 epoch 32 - iter 70/357 - loss 1.56514962 - samples/sec: 265.35\n",
            "2020-04-29 12:28:31,348 epoch 32 - iter 105/357 - loss 1.58820565 - samples/sec: 232.74\n",
            "2020-04-29 12:28:35,718 epoch 32 - iter 140/357 - loss 1.58290052 - samples/sec: 257.77\n",
            "2020-04-29 12:28:39,956 epoch 32 - iter 175/357 - loss 1.59571626 - samples/sec: 265.86\n",
            "2020-04-29 12:28:44,608 epoch 32 - iter 210/357 - loss 1.63206542 - samples/sec: 242.07\n",
            "2020-04-29 12:28:49,162 epoch 32 - iter 245/357 - loss 1.59870562 - samples/sec: 247.10\n",
            "2020-04-29 12:28:53,331 epoch 32 - iter 280/357 - loss 1.60949958 - samples/sec: 270.08\n",
            "2020-04-29 12:28:57,543 epoch 32 - iter 315/357 - loss 1.60741217 - samples/sec: 267.44\n",
            "2020-04-29 12:29:01,976 epoch 32 - iter 350/357 - loss 1.61994082 - samples/sec: 254.16\n",
            "2020-04-29 12:29:02,802 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:29:02,804 EPOCH 32 done: loss 1.6248 - lr 0.1000\n",
            "2020-04-29 12:29:09,069 DEV : loss 1.0461143255233765 - score 0.7726\n",
            "2020-04-29 12:29:46,724 TEST : loss 1.2691664695739746 - score 0.7619\n",
            "2020-04-29 12:29:46,851 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:29:50,110 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:29:54,308 epoch 33 - iter 35/357 - loss 1.52484178 - samples/sec: 267.07\n",
            "2020-04-29 12:29:58,607 epoch 33 - iter 70/357 - loss 1.51340248 - samples/sec: 261.96\n",
            "2020-04-29 12:30:03,467 epoch 33 - iter 105/357 - loss 1.59499836 - samples/sec: 231.46\n",
            "2020-04-29 12:30:08,118 epoch 33 - iter 140/357 - loss 1.57492869 - samples/sec: 242.30\n",
            "2020-04-29 12:30:12,538 epoch 33 - iter 175/357 - loss 1.58936594 - samples/sec: 254.92\n",
            "2020-04-29 12:30:16,780 epoch 33 - iter 210/357 - loss 1.60226822 - samples/sec: 265.64\n",
            "2020-04-29 12:30:20,935 epoch 33 - iter 245/357 - loss 1.59503609 - samples/sec: 271.13\n",
            "2020-04-29 12:30:25,448 epoch 33 - iter 280/357 - loss 1.60267098 - samples/sec: 249.55\n",
            "2020-04-29 12:30:29,958 epoch 33 - iter 315/357 - loss 1.59918222 - samples/sec: 249.86\n",
            "2020-04-29 12:30:34,006 epoch 33 - iter 350/357 - loss 1.59807635 - samples/sec: 278.23\n",
            "2020-04-29 12:30:34,920 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:30:34,921 EPOCH 33 done: loss 1.5998 - lr 0.1000\n",
            "2020-04-29 12:30:43,484 DEV : loss 1.0474404096603394 - score 0.7681\n",
            "2020-04-29 12:31:20,648 TEST : loss 1.2698615789413452 - score 0.7629\n",
            "2020-04-29 12:31:20,775 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 12:31:20,777 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:31:25,017 epoch 34 - iter 35/357 - loss 1.57782453 - samples/sec: 264.47\n",
            "2020-04-29 12:31:29,315 epoch 34 - iter 70/357 - loss 1.55090629 - samples/sec: 261.91\n",
            "2020-04-29 12:31:33,593 epoch 34 - iter 105/357 - loss 1.59527273 - samples/sec: 263.34\n",
            "2020-04-29 12:31:38,100 epoch 34 - iter 140/357 - loss 1.57590425 - samples/sec: 249.72\n",
            "2020-04-29 12:31:42,482 epoch 34 - iter 175/357 - loss 1.59321483 - samples/sec: 256.85\n",
            "2020-04-29 12:31:46,904 epoch 34 - iter 210/357 - loss 1.62500672 - samples/sec: 254.82\n",
            "2020-04-29 12:31:51,161 epoch 34 - iter 245/357 - loss 1.62693535 - samples/sec: 264.51\n",
            "2020-04-29 12:31:55,539 epoch 34 - iter 280/357 - loss 1.61825027 - samples/sec: 257.16\n",
            "2020-04-29 12:31:59,557 epoch 34 - iter 315/357 - loss 1.60590656 - samples/sec: 280.38\n",
            "2020-04-29 12:32:03,772 epoch 34 - iter 350/357 - loss 1.60822599 - samples/sec: 267.20\n",
            "2020-04-29 12:32:04,964 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:32:04,966 EPOCH 34 done: loss 1.6158 - lr 0.1000\n",
            "2020-04-29 12:32:11,773 DEV : loss 1.0379068851470947 - score 0.7659\n",
            "2020-04-29 12:32:48,564 TEST : loss 1.2487343549728394 - score 0.7644\n",
            "2020-04-29 12:32:48,698 BAD EPOCHS (no improvement): 2\n",
            "2020-04-29 12:32:48,700 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:32:52,877 epoch 35 - iter 35/357 - loss 1.67761279 - samples/sec: 268.39\n",
            "2020-04-29 12:32:57,135 epoch 35 - iter 70/357 - loss 1.51026497 - samples/sec: 264.76\n",
            "2020-04-29 12:33:01,579 epoch 35 - iter 105/357 - loss 1.54519859 - samples/sec: 253.29\n",
            "2020-04-29 12:33:05,888 epoch 35 - iter 140/357 - loss 1.57162956 - samples/sec: 261.23\n",
            "2020-04-29 12:33:10,582 epoch 35 - iter 175/357 - loss 1.59821214 - samples/sec: 239.87\n",
            "2020-04-29 12:33:15,124 epoch 35 - iter 210/357 - loss 1.59947319 - samples/sec: 247.80\n",
            "2020-04-29 12:33:19,415 epoch 35 - iter 245/357 - loss 1.59586185 - samples/sec: 262.20\n",
            "2020-04-29 12:33:23,680 epoch 35 - iter 280/357 - loss 1.60319890 - samples/sec: 264.00\n",
            "2020-04-29 12:33:27,868 epoch 35 - iter 315/357 - loss 1.60762013 - samples/sec: 268.93\n",
            "2020-04-29 12:33:32,190 epoch 35 - iter 350/357 - loss 1.59471403 - samples/sec: 260.51\n",
            "2020-04-29 12:33:33,053 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:33:33,054 EPOCH 35 done: loss 1.5981 - lr 0.1000\n",
            "2020-04-29 12:33:39,313 DEV : loss 1.0328233242034912 - score 0.7684\n",
            "2020-04-29 12:34:17,785 TEST : loss 1.2422559261322021 - score 0.7654\n",
            "2020-04-29 12:34:17,926 BAD EPOCHS (no improvement): 3\n",
            "2020-04-29 12:34:17,928 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:34:22,085 epoch 36 - iter 35/357 - loss 1.34639509 - samples/sec: 269.73\n",
            "2020-04-29 12:34:26,329 epoch 36 - iter 70/357 - loss 1.41919087 - samples/sec: 265.40\n",
            "2020-04-29 12:34:30,633 epoch 36 - iter 105/357 - loss 1.48607064 - samples/sec: 261.49\n",
            "2020-04-29 12:34:35,097 epoch 36 - iter 140/357 - loss 1.53026549 - samples/sec: 252.27\n",
            "2020-04-29 12:34:39,722 epoch 36 - iter 175/357 - loss 1.54213535 - samples/sec: 243.66\n",
            "2020-04-29 12:34:44,025 epoch 36 - iter 210/357 - loss 1.55217888 - samples/sec: 261.56\n",
            "2020-04-29 12:34:48,538 epoch 36 - iter 245/357 - loss 1.56242428 - samples/sec: 249.43\n",
            "2020-04-29 12:34:52,697 epoch 36 - iter 280/357 - loss 1.55973210 - samples/sec: 270.75\n",
            "2020-04-29 12:34:57,233 epoch 36 - iter 315/357 - loss 1.57329500 - samples/sec: 248.39\n",
            "2020-04-29 12:35:01,505 epoch 36 - iter 350/357 - loss 1.56904213 - samples/sec: 263.62\n",
            "2020-04-29 12:35:02,472 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:35:02,474 EPOCH 36 done: loss 1.5693 - lr 0.1000\n",
            "2020-04-29 12:35:08,808 DEV : loss 1.0321869850158691 - score 0.7722\n",
            "2020-04-29 12:35:45,905 TEST : loss 1.2336655855178833 - score 0.7662\n",
            "Epoch    36: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-04-29 12:35:46,037 BAD EPOCHS (no improvement): 4\n",
            "2020-04-29 12:35:46,039 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:35:50,256 epoch 37 - iter 35/357 - loss 1.50054827 - samples/sec: 265.88\n",
            "2020-04-29 12:35:54,708 epoch 37 - iter 70/357 - loss 1.54862432 - samples/sec: 252.87\n",
            "2020-04-29 12:35:59,223 epoch 37 - iter 105/357 - loss 1.49299961 - samples/sec: 249.44\n",
            "2020-04-29 12:36:03,315 epoch 37 - iter 140/357 - loss 1.48449366 - samples/sec: 275.21\n",
            "2020-04-29 12:36:07,433 epoch 37 - iter 175/357 - loss 1.48786024 - samples/sec: 273.49\n",
            "2020-04-29 12:36:11,838 epoch 37 - iter 210/357 - loss 1.47125103 - samples/sec: 255.64\n",
            "2020-04-29 12:36:16,172 epoch 37 - iter 245/357 - loss 1.46723009 - samples/sec: 259.81\n",
            "2020-04-29 12:36:20,676 epoch 37 - iter 280/357 - loss 1.47866721 - samples/sec: 250.10\n",
            "2020-04-29 12:36:24,970 epoch 37 - iter 315/357 - loss 1.48363248 - samples/sec: 262.29\n",
            "2020-04-29 12:36:29,331 epoch 37 - iter 350/357 - loss 1.49149672 - samples/sec: 258.23\n",
            "2020-04-29 12:36:30,337 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:36:30,338 EPOCH 37 done: loss 1.4994 - lr 0.0500\n",
            "2020-04-29 12:36:37,018 DEV : loss 0.9944227933883667 - score 0.7754\n",
            "2020-04-29 12:37:14,261 TEST : loss 1.203306794166565 - score 0.7694\n",
            "2020-04-29 12:37:14,390 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:37:17,590 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:37:22,248 epoch 38 - iter 35/357 - loss 1.50386713 - samples/sec: 240.70\n",
            "2020-04-29 12:37:26,813 epoch 38 - iter 70/357 - loss 1.46427468 - samples/sec: 246.66\n",
            "2020-04-29 12:37:31,084 epoch 38 - iter 105/357 - loss 1.47218343 - samples/sec: 263.78\n",
            "2020-04-29 12:37:35,258 epoch 38 - iter 140/357 - loss 1.48929087 - samples/sec: 269.87\n",
            "2020-04-29 12:37:39,839 epoch 38 - iter 175/357 - loss 1.48404831 - samples/sec: 245.74\n",
            "2020-04-29 12:37:44,312 epoch 38 - iter 210/357 - loss 1.47170304 - samples/sec: 251.75\n",
            "2020-04-29 12:37:48,512 epoch 38 - iter 245/357 - loss 1.48368304 - samples/sec: 268.64\n",
            "2020-04-29 12:37:53,180 epoch 38 - iter 280/357 - loss 1.48806695 - samples/sec: 241.05\n",
            "2020-04-29 12:37:57,599 epoch 38 - iter 315/357 - loss 1.48267922 - samples/sec: 254.86\n",
            "2020-04-29 12:38:01,935 epoch 38 - iter 350/357 - loss 1.47631251 - samples/sec: 259.73\n",
            "2020-04-29 12:38:02,991 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:38:02,992 EPOCH 38 done: loss 1.4761 - lr 0.0500\n",
            "2020-04-29 12:38:09,435 DEV : loss 0.9974281787872314 - score 0.7757\n",
            "2020-04-29 12:38:49,322 TEST : loss 1.2004529237747192 - score 0.771\n",
            "2020-04-29 12:38:49,461 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:38:52,654 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:38:57,131 epoch 39 - iter 35/357 - loss 1.33846162 - samples/sec: 250.45\n",
            "2020-04-29 12:39:01,476 epoch 39 - iter 70/357 - loss 1.39993601 - samples/sec: 259.18\n",
            "2020-04-29 12:39:06,104 epoch 39 - iter 105/357 - loss 1.42005796 - samples/sec: 243.13\n",
            "2020-04-29 12:39:10,462 epoch 39 - iter 140/357 - loss 1.43211591 - samples/sec: 258.68\n",
            "2020-04-29 12:39:14,465 epoch 39 - iter 175/357 - loss 1.44383884 - samples/sec: 281.43\n",
            "2020-04-29 12:39:18,936 epoch 39 - iter 210/357 - loss 1.46266035 - samples/sec: 251.96\n",
            "2020-04-29 12:39:23,112 epoch 39 - iter 245/357 - loss 1.45785129 - samples/sec: 269.92\n",
            "2020-04-29 12:39:27,579 epoch 39 - iter 280/357 - loss 1.45722546 - samples/sec: 251.97\n",
            "2020-04-29 12:39:31,969 epoch 39 - iter 315/357 - loss 1.46359514 - samples/sec: 256.34\n",
            "2020-04-29 12:39:36,551 epoch 39 - iter 350/357 - loss 1.45988436 - samples/sec: 245.76\n",
            "2020-04-29 12:39:37,365 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:39:37,367 EPOCH 39 done: loss 1.4555 - lr 0.0500\n",
            "2020-04-29 12:39:43,815 DEV : loss 1.0000557899475098 - score 0.781\n",
            "2020-04-29 12:40:20,823 TEST : loss 1.2148499488830566 - score 0.7716\n",
            "2020-04-29 12:40:20,954 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:40:24,131 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:40:28,494 epoch 40 - iter 35/357 - loss 1.42013391 - samples/sec: 257.01\n",
            "2020-04-29 12:40:32,569 epoch 40 - iter 70/357 - loss 1.39634956 - samples/sec: 276.63\n",
            "2020-04-29 12:40:36,861 epoch 40 - iter 105/357 - loss 1.40658075 - samples/sec: 262.35\n",
            "2020-04-29 12:40:40,866 epoch 40 - iter 140/357 - loss 1.39236273 - samples/sec: 281.20\n",
            "2020-04-29 12:40:44,995 epoch 40 - iter 175/357 - loss 1.39316255 - samples/sec: 272.55\n",
            "2020-04-29 12:40:49,253 epoch 40 - iter 210/357 - loss 1.39096028 - samples/sec: 264.27\n",
            "2020-04-29 12:40:53,833 epoch 40 - iter 245/357 - loss 1.41870758 - samples/sec: 245.85\n",
            "2020-04-29 12:40:58,865 epoch 40 - iter 280/357 - loss 1.42991700 - samples/sec: 223.63\n",
            "2020-04-29 12:41:03,098 epoch 40 - iter 315/357 - loss 1.43131264 - samples/sec: 266.03\n",
            "2020-04-29 12:41:07,288 epoch 40 - iter 350/357 - loss 1.44301934 - samples/sec: 269.02\n",
            "2020-04-29 12:41:08,041 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:41:08,043 EPOCH 40 done: loss 1.4440 - lr 0.0500\n",
            "2020-04-29 12:41:14,380 DEV : loss 1.023829460144043 - score 0.7703\n",
            "2020-04-29 12:41:51,018 TEST : loss 1.2207485437393188 - score 0.7694\n",
            "2020-04-29 12:41:51,139 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 12:41:51,141 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:41:55,577 epoch 41 - iter 35/357 - loss 1.37483152 - samples/sec: 252.71\n",
            "2020-04-29 12:41:59,775 epoch 41 - iter 70/357 - loss 1.47316913 - samples/sec: 268.18\n",
            "2020-04-29 12:42:04,014 epoch 41 - iter 105/357 - loss 1.43341008 - samples/sec: 266.30\n",
            "2020-04-29 12:42:08,318 epoch 41 - iter 140/357 - loss 1.44321580 - samples/sec: 261.71\n",
            "2020-04-29 12:42:12,577 epoch 41 - iter 175/357 - loss 1.43522525 - samples/sec: 264.26\n",
            "2020-04-29 12:42:16,881 epoch 41 - iter 210/357 - loss 1.43408627 - samples/sec: 261.43\n",
            "2020-04-29 12:42:21,254 epoch 41 - iter 245/357 - loss 1.43442073 - samples/sec: 257.61\n",
            "2020-04-29 12:42:25,335 epoch 41 - iter 280/357 - loss 1.43102271 - samples/sec: 275.86\n",
            "2020-04-29 12:42:29,642 epoch 41 - iter 315/357 - loss 1.43827779 - samples/sec: 261.42\n",
            "2020-04-29 12:42:33,721 epoch 41 - iter 350/357 - loss 1.43452510 - samples/sec: 276.25\n",
            "2020-04-29 12:42:34,658 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:42:34,661 EPOCH 41 done: loss 1.4315 - lr 0.0500\n",
            "2020-04-29 12:42:41,531 DEV : loss 0.9764143228530884 - score 0.7799\n",
            "2020-04-29 12:43:20,489 TEST : loss 1.1919351816177368 - score 0.7749\n",
            "2020-04-29 12:43:20,613 BAD EPOCHS (no improvement): 2\n",
            "2020-04-29 12:43:20,615 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:43:24,877 epoch 42 - iter 35/357 - loss 1.34068391 - samples/sec: 263.10\n",
            "2020-04-29 12:43:28,902 epoch 42 - iter 70/357 - loss 1.30453930 - samples/sec: 280.10\n",
            "2020-04-29 12:43:33,327 epoch 42 - iter 105/357 - loss 1.31786520 - samples/sec: 254.83\n",
            "2020-04-29 12:43:37,553 epoch 42 - iter 140/357 - loss 1.36266114 - samples/sec: 266.45\n",
            "2020-04-29 12:43:41,923 epoch 42 - iter 175/357 - loss 1.37889189 - samples/sec: 257.73\n",
            "2020-04-29 12:43:46,270 epoch 42 - iter 210/357 - loss 1.37276506 - samples/sec: 259.21\n",
            "2020-04-29 12:43:50,998 epoch 42 - iter 245/357 - loss 1.38075099 - samples/sec: 238.05\n",
            "2020-04-29 12:43:55,134 epoch 42 - iter 280/357 - loss 1.40831172 - samples/sec: 272.38\n",
            "2020-04-29 12:43:59,668 epoch 42 - iter 315/357 - loss 1.41179607 - samples/sec: 248.34\n",
            "2020-04-29 12:44:04,368 epoch 42 - iter 350/357 - loss 1.41486920 - samples/sec: 239.50\n",
            "2020-04-29 12:44:05,141 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:44:05,143 EPOCH 42 done: loss 1.4156 - lr 0.0500\n",
            "2020-04-29 12:44:11,375 DEV : loss 0.9879021644592285 - score 0.7805\n",
            "2020-04-29 12:44:48,317 TEST : loss 1.1977200508117676 - score 0.776\n",
            "2020-04-29 12:44:48,443 BAD EPOCHS (no improvement): 3\n",
            "2020-04-29 12:44:48,445 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:44:52,937 epoch 43 - iter 35/357 - loss 1.41285052 - samples/sec: 249.53\n",
            "2020-04-29 12:44:57,162 epoch 43 - iter 70/357 - loss 1.38859374 - samples/sec: 266.48\n",
            "2020-04-29 12:45:01,635 epoch 43 - iter 105/357 - loss 1.42700300 - samples/sec: 251.65\n",
            "2020-04-29 12:45:05,850 epoch 43 - iter 140/357 - loss 1.43510121 - samples/sec: 266.94\n",
            "2020-04-29 12:45:10,266 epoch 43 - iter 175/357 - loss 1.40879905 - samples/sec: 255.03\n",
            "2020-04-29 12:45:14,287 epoch 43 - iter 210/357 - loss 1.38994065 - samples/sec: 280.30\n",
            "2020-04-29 12:45:18,445 epoch 43 - iter 245/357 - loss 1.39641225 - samples/sec: 270.98\n",
            "2020-04-29 12:45:22,672 epoch 43 - iter 280/357 - loss 1.39616926 - samples/sec: 266.46\n",
            "2020-04-29 12:45:27,001 epoch 43 - iter 315/357 - loss 1.38571029 - samples/sec: 260.06\n",
            "2020-04-29 12:45:31,457 epoch 43 - iter 350/357 - loss 1.39530566 - samples/sec: 252.43\n",
            "2020-04-29 12:45:32,572 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:45:32,574 EPOCH 43 done: loss 1.3926 - lr 0.0500\n",
            "2020-04-29 12:45:38,980 DEV : loss 0.9880927801132202 - score 0.7838\n",
            "2020-04-29 12:46:16,557 TEST : loss 1.1910597085952759 - score 0.7784\n",
            "2020-04-29 12:46:16,688 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:46:19,840 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:46:24,382 epoch 44 - iter 35/357 - loss 1.36072381 - samples/sec: 246.88\n",
            "2020-04-29 12:46:28,668 epoch 44 - iter 70/357 - loss 1.33147116 - samples/sec: 262.52\n",
            "2020-04-29 12:46:33,181 epoch 44 - iter 105/357 - loss 1.36195150 - samples/sec: 249.48\n",
            "2020-04-29 12:46:37,232 epoch 44 - iter 140/357 - loss 1.35856054 - samples/sec: 277.95\n",
            "2020-04-29 12:46:41,882 epoch 44 - iter 175/357 - loss 1.37083431 - samples/sec: 242.04\n",
            "2020-04-29 12:46:46,626 epoch 44 - iter 210/357 - loss 1.38467509 - samples/sec: 237.39\n",
            "2020-04-29 12:46:51,054 epoch 44 - iter 245/357 - loss 1.39527333 - samples/sec: 254.29\n",
            "2020-04-29 12:46:55,641 epoch 44 - iter 280/357 - loss 1.39720970 - samples/sec: 245.41\n",
            "2020-04-29 12:47:00,112 epoch 44 - iter 315/357 - loss 1.40891648 - samples/sec: 251.90\n",
            "2020-04-29 12:47:04,303 epoch 44 - iter 350/357 - loss 1.39660904 - samples/sec: 268.89\n",
            "2020-04-29 12:47:05,276 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:47:05,278 EPOCH 44 done: loss 1.3975 - lr 0.0500\n",
            "2020-04-29 12:47:11,827 DEV : loss 0.9845936298370361 - score 0.7822\n",
            "2020-04-29 12:47:48,986 TEST : loss 1.2040925025939941 - score 0.7755\n",
            "2020-04-29 12:47:49,108 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 12:47:49,110 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:47:53,210 epoch 45 - iter 35/357 - loss 1.33432199 - samples/sec: 273.69\n",
            "2020-04-29 12:47:57,730 epoch 45 - iter 70/357 - loss 1.33975398 - samples/sec: 249.10\n",
            "2020-04-29 12:48:01,895 epoch 45 - iter 105/357 - loss 1.36833979 - samples/sec: 270.39\n",
            "2020-04-29 12:48:05,972 epoch 45 - iter 140/357 - loss 1.35781295 - samples/sec: 276.14\n",
            "2020-04-29 12:48:10,621 epoch 45 - iter 175/357 - loss 1.36114114 - samples/sec: 242.40\n",
            "2020-04-29 12:48:14,565 epoch 45 - iter 210/357 - loss 1.36090132 - samples/sec: 285.47\n",
            "2020-04-29 12:48:18,791 epoch 45 - iter 245/357 - loss 1.37082889 - samples/sec: 266.47\n",
            "2020-04-29 12:48:22,812 epoch 45 - iter 280/357 - loss 1.36937117 - samples/sec: 280.34\n",
            "2020-04-29 12:48:26,951 epoch 45 - iter 315/357 - loss 1.39186856 - samples/sec: 271.83\n",
            "2020-04-29 12:48:31,794 epoch 45 - iter 350/357 - loss 1.40213132 - samples/sec: 232.22\n",
            "2020-04-29 12:48:32,672 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:48:32,674 EPOCH 45 done: loss 1.4039 - lr 0.0500\n",
            "2020-04-29 12:48:39,057 DEV : loss 0.9872748851776123 - score 0.7797\n",
            "2020-04-29 12:49:14,228 TEST : loss 1.1916124820709229 - score 0.7765\n",
            "2020-04-29 12:49:14,354 BAD EPOCHS (no improvement): 2\n",
            "2020-04-29 12:49:14,355 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:49:18,506 epoch 46 - iter 35/357 - loss 1.37761291 - samples/sec: 270.28\n",
            "2020-04-29 12:49:22,491 epoch 46 - iter 70/357 - loss 1.38098989 - samples/sec: 283.08\n",
            "2020-04-29 12:49:26,744 epoch 46 - iter 105/357 - loss 1.39517997 - samples/sec: 264.56\n",
            "2020-04-29 12:49:31,124 epoch 46 - iter 140/357 - loss 1.39820219 - samples/sec: 257.22\n",
            "2020-04-29 12:49:35,238 epoch 46 - iter 175/357 - loss 1.40517642 - samples/sec: 273.75\n",
            "2020-04-29 12:49:39,521 epoch 46 - iter 210/357 - loss 1.40325680 - samples/sec: 263.15\n",
            "2020-04-29 12:49:43,576 epoch 46 - iter 245/357 - loss 1.37909673 - samples/sec: 277.79\n",
            "2020-04-29 12:49:47,627 epoch 46 - iter 280/357 - loss 1.37480488 - samples/sec: 277.99\n",
            "2020-04-29 12:49:51,820 epoch 46 - iter 315/357 - loss 1.36711268 - samples/sec: 268.34\n",
            "2020-04-29 12:49:55,747 epoch 46 - iter 350/357 - loss 1.37814135 - samples/sec: 286.68\n",
            "2020-04-29 12:49:56,547 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:49:56,548 EPOCH 46 done: loss 1.3757 - lr 0.0500\n",
            "2020-04-29 12:50:02,640 DEV : loss 0.9640588760375977 - score 0.7849\n",
            "2020-04-29 12:50:40,769 TEST : loss 1.1808584928512573 - score 0.7777\n",
            "2020-04-29 12:50:40,891 BAD EPOCHS (no improvement): 0\n",
            "2020-04-29 12:50:44,078 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:50:48,760 epoch 47 - iter 35/357 - loss 1.53014381 - samples/sec: 239.45\n",
            "2020-04-29 12:50:52,733 epoch 47 - iter 70/357 - loss 1.41394333 - samples/sec: 283.77\n",
            "2020-04-29 12:50:57,241 epoch 47 - iter 105/357 - loss 1.39598347 - samples/sec: 249.49\n",
            "2020-04-29 12:51:01,287 epoch 47 - iter 140/357 - loss 1.39702187 - samples/sec: 278.39\n",
            "2020-04-29 12:51:05,348 epoch 47 - iter 175/357 - loss 1.39902747 - samples/sec: 277.28\n",
            "2020-04-29 12:51:09,680 epoch 47 - iter 210/357 - loss 1.38384172 - samples/sec: 259.89\n",
            "2020-04-29 12:51:14,054 epoch 47 - iter 245/357 - loss 1.40176935 - samples/sec: 257.43\n",
            "2020-04-29 12:51:18,360 epoch 47 - iter 280/357 - loss 1.39601743 - samples/sec: 261.59\n",
            "2020-04-29 12:51:22,462 epoch 47 - iter 315/357 - loss 1.38879186 - samples/sec: 274.65\n",
            "2020-04-29 12:51:26,649 epoch 47 - iter 350/357 - loss 1.38696417 - samples/sec: 269.22\n",
            "2020-04-29 12:51:27,863 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:51:27,864 EPOCH 47 done: loss 1.3918 - lr 0.0500\n",
            "2020-04-29 12:51:34,216 DEV : loss 0.9688778519630432 - score 0.7841\n",
            "2020-04-29 12:52:09,632 TEST : loss 1.1819250583648682 - score 0.7792\n",
            "2020-04-29 12:52:09,752 BAD EPOCHS (no improvement): 1\n",
            "2020-04-29 12:52:09,754 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:52:13,934 epoch 48 - iter 35/357 - loss 1.39261304 - samples/sec: 268.20\n",
            "2020-04-29 12:52:18,286 epoch 48 - iter 70/357 - loss 1.37282412 - samples/sec: 259.19\n",
            "2020-04-29 12:52:22,665 epoch 48 - iter 105/357 - loss 1.36333250 - samples/sec: 257.07\n",
            "2020-04-29 12:52:26,842 epoch 48 - iter 140/357 - loss 1.35213393 - samples/sec: 269.45\n",
            "2020-04-29 12:52:31,162 epoch 48 - iter 175/357 - loss 1.38200367 - samples/sec: 260.72\n",
            "2020-04-29 12:52:35,416 epoch 48 - iter 210/357 - loss 1.37229986 - samples/sec: 264.71\n",
            "2020-04-29 12:52:39,739 epoch 48 - iter 245/357 - loss 1.37812777 - samples/sec: 260.47\n",
            "2020-04-29 12:52:44,356 epoch 48 - iter 280/357 - loss 1.38354270 - samples/sec: 243.70\n",
            "2020-04-29 12:52:48,751 epoch 48 - iter 315/357 - loss 1.38962585 - samples/sec: 256.20\n",
            "2020-04-29 12:52:52,937 epoch 48 - iter 350/357 - loss 1.37368583 - samples/sec: 269.11\n",
            "2020-04-29 12:52:53,765 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:52:53,766 EPOCH 48 done: loss 1.3681 - lr 0.0500\n",
            "2020-04-29 12:53:00,018 DEV : loss 0.9727956652641296 - score 0.7844\n",
            "2020-04-29 12:53:35,694 TEST : loss 1.1887474060058594 - score 0.7778\n",
            "2020-04-29 12:53:35,818 BAD EPOCHS (no improvement): 2\n",
            "2020-04-29 12:53:35,820 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:53:39,916 epoch 49 - iter 35/357 - loss 1.28905161 - samples/sec: 273.85\n",
            "2020-04-29 12:53:44,245 epoch 49 - iter 70/357 - loss 1.32930628 - samples/sec: 260.38\n",
            "2020-04-29 12:53:48,297 epoch 49 - iter 105/357 - loss 1.31017171 - samples/sec: 277.99\n",
            "2020-04-29 12:53:52,629 epoch 49 - iter 140/357 - loss 1.33782307 - samples/sec: 259.84\n",
            "2020-04-29 12:53:56,817 epoch 49 - iter 175/357 - loss 1.34714770 - samples/sec: 268.97\n",
            "2020-04-29 12:54:01,159 epoch 49 - iter 210/357 - loss 1.36933444 - samples/sec: 259.30\n",
            "2020-04-29 12:54:05,578 epoch 49 - iter 245/357 - loss 1.39749159 - samples/sec: 254.69\n",
            "2020-04-29 12:54:09,628 epoch 49 - iter 280/357 - loss 1.38993774 - samples/sec: 277.93\n",
            "2020-04-29 12:54:13,577 epoch 49 - iter 315/357 - loss 1.36261127 - samples/sec: 285.49\n",
            "2020-04-29 12:54:17,810 epoch 49 - iter 350/357 - loss 1.36330597 - samples/sec: 266.10\n",
            "2020-04-29 12:54:18,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:54:18,735 EPOCH 49 done: loss 1.3643 - lr 0.0500\n",
            "2020-04-29 12:54:25,056 DEV : loss 0.9657993912696838 - score 0.7814\n",
            "2020-04-29 12:55:02,205 TEST : loss 1.174793004989624 - score 0.78\n",
            "2020-04-29 12:55:02,327 BAD EPOCHS (no improvement): 3\n",
            "2020-04-29 12:55:02,329 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:55:06,998 epoch 50 - iter 35/357 - loss 1.28506226 - samples/sec: 240.13\n",
            "2020-04-29 12:55:11,075 epoch 50 - iter 70/357 - loss 1.30798278 - samples/sec: 276.35\n",
            "2020-04-29 12:55:15,269 epoch 50 - iter 105/357 - loss 1.35656931 - samples/sec: 268.51\n",
            "2020-04-29 12:55:19,555 epoch 50 - iter 140/357 - loss 1.36250386 - samples/sec: 262.81\n",
            "2020-04-29 12:55:23,983 epoch 50 - iter 175/357 - loss 1.34272218 - samples/sec: 254.12\n",
            "2020-04-29 12:55:28,031 epoch 50 - iter 210/357 - loss 1.32460687 - samples/sec: 278.11\n",
            "2020-04-29 12:55:32,146 epoch 50 - iter 245/357 - loss 1.34306288 - samples/sec: 273.80\n",
            "2020-04-29 12:55:36,473 epoch 50 - iter 280/357 - loss 1.33467733 - samples/sec: 260.47\n",
            "2020-04-29 12:55:40,864 epoch 50 - iter 315/357 - loss 1.34789612 - samples/sec: 256.69\n",
            "2020-04-29 12:55:45,024 epoch 50 - iter 350/357 - loss 1.35557256 - samples/sec: 270.67\n",
            "2020-04-29 12:55:45,831 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:55:45,832 EPOCH 50 done: loss 1.3559 - lr 0.0500\n",
            "2020-04-29 12:55:51,937 DEV : loss 0.9759340286254883 - score 0.7808\n",
            "2020-04-29 12:56:27,326 TEST : loss 1.1770200729370117 - score 0.7779\n",
            "Epoch    50: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-04-29 12:56:27,446 BAD EPOCHS (no improvement): 4\n",
            "2020-04-29 12:56:30,530 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-29 12:56:30,531 Testing using best model ...\n",
            "2020-04-29 12:56:30,534 loading file resources/taggers/example-ner/best-model.pt\n",
            "2020-04-29 12:57:09,251 0.7955\t0.7607\t0.7777\n",
            "2020-04-29 12:57:09,252 \n",
            "MICRO_AVG: acc 0.6363 - f1-score 0.7777\n",
            "MACRO_AVG: acc 0.6396 - f1-score 0.7798333333333334\n",
            "problem    tp: 9479 - fp: 2854 - fn: 3113 - tn: 9479 - precision: 0.7686 - recall: 0.7528 - accuracy: 0.6137 - f1-score: 0.7606\n",
            "test       tp: 7365 - fp: 1591 - fn: 1860 - tn: 7365 - precision: 0.8224 - recall: 0.7984 - accuracy: 0.6809 - f1-score: 0.8102\n",
            "treatment  tp: 6861 - fp: 1647 - fn: 2483 - tn: 6861 - precision: 0.8064 - recall: 0.7343 - accuracy: 0.6242 - f1-score: 0.7687\n",
            "2020-04-29 12:57:09,254 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(2.7825, device='cuda:0'),\n",
              "  tensor(2.3154, device='cuda:0'),\n",
              "  tensor(2.0501, device='cuda:0'),\n",
              "  tensor(1.9109, device='cuda:0'),\n",
              "  tensor(1.9561, device='cuda:0'),\n",
              "  tensor(1.6659, device='cuda:0'),\n",
              "  tensor(1.6093, device='cuda:0'),\n",
              "  tensor(1.5244, device='cuda:0'),\n",
              "  tensor(1.4786, device='cuda:0'),\n",
              "  tensor(1.4824, device='cuda:0'),\n",
              "  tensor(1.4258, device='cuda:0'),\n",
              "  tensor(1.3320, device='cuda:0'),\n",
              "  tensor(1.4113, device='cuda:0'),\n",
              "  tensor(1.3018, device='cuda:0'),\n",
              "  tensor(1.3333, device='cuda:0'),\n",
              "  tensor(1.3124, device='cuda:0'),\n",
              "  tensor(1.2760, device='cuda:0'),\n",
              "  tensor(1.2263, device='cuda:0'),\n",
              "  tensor(1.1834, device='cuda:0'),\n",
              "  tensor(1.2294, device='cuda:0'),\n",
              "  tensor(1.1906, device='cuda:0'),\n",
              "  tensor(1.1716, device='cuda:0'),\n",
              "  tensor(1.1540, device='cuda:0'),\n",
              "  tensor(1.1256, device='cuda:0'),\n",
              "  tensor(1.1346, device='cuda:0'),\n",
              "  tensor(1.1013, device='cuda:0'),\n",
              "  tensor(1.0833, device='cuda:0'),\n",
              "  tensor(1.2150, device='cuda:0'),\n",
              "  tensor(1.1035, device='cuda:0'),\n",
              "  tensor(1.0841, device='cuda:0'),\n",
              "  tensor(1.0816, device='cuda:0'),\n",
              "  tensor(1.0461, device='cuda:0'),\n",
              "  tensor(1.0474, device='cuda:0'),\n",
              "  tensor(1.0379, device='cuda:0'),\n",
              "  tensor(1.0328, device='cuda:0'),\n",
              "  tensor(1.0322, device='cuda:0'),\n",
              "  tensor(0.9944, device='cuda:0'),\n",
              "  tensor(0.9974, device='cuda:0'),\n",
              "  tensor(1.0001, device='cuda:0'),\n",
              "  tensor(1.0238, device='cuda:0'),\n",
              "  tensor(0.9764, device='cuda:0'),\n",
              "  tensor(0.9879, device='cuda:0'),\n",
              "  tensor(0.9881, device='cuda:0'),\n",
              "  tensor(0.9846, device='cuda:0'),\n",
              "  tensor(0.9873, device='cuda:0'),\n",
              "  tensor(0.9641, device='cuda:0'),\n",
              "  tensor(0.9689, device='cuda:0'),\n",
              "  tensor(0.9728, device='cuda:0'),\n",
              "  tensor(0.9658, device='cuda:0'),\n",
              "  tensor(0.9759, device='cuda:0')],\n",
              " 'dev_score_history': [0.4507,\n",
              "  0.5225,\n",
              "  0.5618,\n",
              "  0.5856,\n",
              "  0.5904,\n",
              "  0.6424,\n",
              "  0.6487,\n",
              "  0.6669,\n",
              "  0.6727,\n",
              "  0.6708,\n",
              "  0.6834,\n",
              "  0.7046,\n",
              "  0.6955,\n",
              "  0.716,\n",
              "  0.7114,\n",
              "  0.7122,\n",
              "  0.7224,\n",
              "  0.7245,\n",
              "  0.7328,\n",
              "  0.732,\n",
              "  0.7383,\n",
              "  0.7367,\n",
              "  0.7449,\n",
              "  0.7493,\n",
              "  0.747,\n",
              "  0.7546,\n",
              "  0.7562,\n",
              "  0.74,\n",
              "  0.755,\n",
              "  0.7555,\n",
              "  0.7603,\n",
              "  0.7726,\n",
              "  0.7681,\n",
              "  0.7659,\n",
              "  0.7684,\n",
              "  0.7722,\n",
              "  0.7754,\n",
              "  0.7757,\n",
              "  0.781,\n",
              "  0.7703,\n",
              "  0.7799,\n",
              "  0.7805,\n",
              "  0.7838,\n",
              "  0.7822,\n",
              "  0.7797,\n",
              "  0.7849,\n",
              "  0.7841,\n",
              "  0.7844,\n",
              "  0.7814,\n",
              "  0.7808],\n",
              " 'test_score': 0.7777,\n",
              " 'train_loss_history': [4.815176835247114,\n",
              "  3.2229939669120213,\n",
              "  2.8700709137596,\n",
              "  2.7092285403350487,\n",
              "  2.557973112044882,\n",
              "  2.4803112501523743,\n",
              "  2.3840322688180193,\n",
              "  2.3087491504952355,\n",
              "  2.2311615160867277,\n",
              "  2.180980824789747,\n",
              "  2.1418284333052755,\n",
              "  2.0783654038979558,\n",
              "  2.034377962601285,\n",
              "  2.0223571306684103,\n",
              "  1.9968008098482084,\n",
              "  1.9556890211853326,\n",
              "  1.9021645518911987,\n",
              "  1.8852656712385119,\n",
              "  1.8556972710358328,\n",
              "  1.8654345519402449,\n",
              "  1.8338355477116688,\n",
              "  1.7986574511902005,\n",
              "  1.7709032753769423,\n",
              "  1.749440863185904,\n",
              "  1.7576358603830098,\n",
              "  1.7186497602643085,\n",
              "  1.6796519392344798,\n",
              "  1.7100638592777466,\n",
              "  1.6757426086594076,\n",
              "  1.6648329942166304,\n",
              "  1.6364752007465737,\n",
              "  1.6247981509574656,\n",
              "  1.5998321494468455,\n",
              "  1.6157793403506613,\n",
              "  1.5981246126966984,\n",
              "  1.5692988652475073,\n",
              "  1.4993991869337417,\n",
              "  1.4761280970079225,\n",
              "  1.45553218441851,\n",
              "  1.444011655675263,\n",
              "  1.4315195059408994,\n",
              "  1.4155928824796062,\n",
              "  1.3926226129384935,\n",
              "  1.397458038243259,\n",
              "  1.4039424828120641,\n",
              "  1.3756771642787784,\n",
              "  1.3917536556052894,\n",
              "  1.368083387947216,\n",
              "  1.3643403882239045,\n",
              "  1.3558757962966834]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T84CWvMw1dEB",
        "colab_type": "code",
        "outputId": "7b1d78fe-c45b-4cec-9eb4-2ba7d26fcc2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "result, _ = sequencetagger.evaluate([corpus.test])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0c3daca10b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequencetagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data_loader, out_path, embedding_storage_mode)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                     tags, _ = self._obtain_labels(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             sentence_tensor, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n\u001b[0;32m--> 559\u001b[0;31m                 \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m             )\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_packed_sequence\u001b[0;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munsorted_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpadded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munsorted_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpadded_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 10.75 GiB (GPU 0; 15.90 GiB total capacity; 13.60 GiB already allocated; 13.88 MiB free; 15.11 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzedRd301dBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this is CONll eval style - exact match \n",
        "print(result.detailed_results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV-PPBIiVRxw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdp4nrSdwOom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: implement inexact match evaluation - token level"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei7y0g5kIGhI",
        "colab_type": "code",
        "outputId": "e3d4f330-3522-4c1c-fb0d-2e1727345905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = SequenceTagger.load('resources/taggers/example-ner/final-model.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-14 09:58:47,509 loading file resources/taggers/example-ner/final-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqCwHKr2IGuY",
        "colab_type": "code",
        "outputId": "60b8465d-add4-4e0f-951a-a2f213c2919c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.tag_type"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ner'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqTbxHeIIG0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.tag_type = 'predicted_ner'\n",
        "\n",
        "# predict tags\n",
        "pred = model.predict(corpus.test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyyQnMboIGy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka9Zzja7IGxZ",
        "colab_type": "code",
        "outputId": "31636a59-ba38-46bb-c982-67a20d7d6962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred[36].to_tagged_string('predicted_ner')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5.) LBBB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDlkGESxIZ0E",
        "colab_type": "code",
        "outputId": "1126cc36-0d8f-47fe-99f1-5a0986880362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred[36].to_tagged_string('ner')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5.) LBBB <B-problem>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEKCRil2JC44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}